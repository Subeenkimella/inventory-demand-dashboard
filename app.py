# test commit - 

import os
import re
import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
import math

st.set_page_config(page_title="ì¬ê³ Â·ìˆ˜ìš” ìš´ì˜ ëŒ€ì‹œë³´ë“œ", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
  [data-testid="stSidebar"] { font-size: 0.8125rem; }
  h1 { font-size: 1.85rem !important; font-weight: 600; margin-bottom: 0.25rem !important; }
  h2 { font-size: 1.25rem !important; font-weight: 600; margin-top: 1.25rem !important; }
  [data-testid="stMetricValue"] { font-size: 1.5rem !important; font-weight: 600; }
  [data-testid="stMetricLabel"] { font-size: 0.9rem !important; color: #555; }
  .stCaptionContainer { font-size: 0.85rem !important; color: #666; }
  .header-info-box {
    padding: 0.6rem 0.9rem;
    border-radius: 8px;
    font-size: 0.8rem;
    line-height: 1.4;
    margin-bottom: 0.5rem;
    border: 1px solid #e2e8f0;
    background: #f8fafc;
  }
  .header-info-box .label { font-weight: 600; color: #64748b; font-size: 0.7rem; text-transform: uppercase; letter-spacing: 0.03em; margin-bottom: 0.2rem; }
  .header-info-box .value { color: #0f172a; }
</style>
""", unsafe_allow_html=True)


def apply_plotly_theme(fig):
    fig.update_layout(
        template="plotly_white",
        font=dict(size=13),
        margin=dict(l=40, r=20, t=60, b=40),
        xaxis=dict(showgrid=True, gridcolor="#e5e5e5"),
        yaxis=dict(showgrid=True, gridcolor="#e5e5e5", tickformat=",.0f"),
    )
    return fig


def add_ref_hline(fig, y, label, line_dash="dash", line_color="gray"):
    fig.add_hline(y=y, line_dash=line_dash, line_color=line_color)
    fig.add_annotation(x=1, y=y, xref="paper", yref="y", text=label, showarrow=False, xanchor="right", yanchor="bottom")
    return fig


def add_ref_vline(fig, x, label, line_dash="dash", line_color="gray"):
    try:
        x_safe = float(pd.to_numeric(x, errors="coerce")) if pd.notna(x) else None
    except Exception:
        x_safe = x
    if x_safe is not None:
        fig.add_vline(x=x_safe, line_dash=line_dash, line_color=line_color)
        fig.add_annotation(x=x_safe, y=1, xref="x", yref="paper", text=label, showarrow=False, yanchor="bottom", xanchor="left")
    return fig


def fmt_qty(v):
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return f"{int(v):,}"


def fmt_days(v):
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return f"{float(v):.1f}"


def fmt_date(v):
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return str(pd.to_datetime(v).date()) if hasattr(pd.to_datetime(v), "date") else str(v)


def _data_file_mtime():
    """CSV ìˆ˜ì • ì‹œ ìºì‹œê°€ ë¬´íš¨í™”ë˜ë„ë¡ íŒŒì¼ mtimeì„ ìºì‹œ í‚¤ë¡œ ì‚¬ìš©."""
    t1 = os.path.getmtime("inventory_daily.csv") if os.path.exists("inventory_daily.csv") else 0
    t2 = os.path.getmtime("demand_daily.csv") if os.path.exists("demand_daily.csv") else 0
    return (t1, t2)


@st.cache_data
def load_data(_cache_key):
    sku = pd.read_csv("sku_master.csv")
    demand = pd.read_csv("demand_daily.csv", parse_dates=["date"])
    inv = pd.read_csv("inventory_daily.csv", parse_dates=["date"])
    try:
        inv_txn = pd.read_csv("inventory_txn.csv", parse_dates=["date", "txn_datetime"])
    except FileNotFoundError:
        inv_txn = pd.DataFrame(columns=["txn_datetime", "date", "sku", "warehouse", "txn_type", "qty", "ref_id", "reason_code"])
    return sku, demand, inv, inv_txn


def compute_forecast(demand_df, sku_df, cat, wh, sku_pick, base_date_str, horizon_days=60, lookback_days=180, window_days=14):
    """
    ê°„ë‹¨í•œ ìˆ˜ìš” ì˜ˆì¸¡: Moving Average ê¸°ë°˜.
    - ìµœê·¼ lookback_days êµ¬ê°„ì—ì„œ SKUë³„ ì¼ë³„ ìˆ˜ìš” ì‚¬ìš©
    - ê° SKUë³„ ìµœê·¼ window_days í‰ê·  ìˆ˜ìš”ë¥¼ horizon_days ê¸°ê°„ ë™ì•ˆ ê³ ì • ì˜ˆì¸¡
    - ì°½ê³  í•„í„°(wh)ëŠ” ì˜ˆì¸¡ ëŒ€ìƒ SKUë§Œ ì œí•œí•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš© (ìˆ˜ìš”ëŠ” ì „ì²´ í•©ê³„ ê¸°ì¤€)
    """
    if demand_df is None or demand_df.empty:
        return pd.DataFrame(columns=["date", "sku", "forecast_qty"])
    latest = pd.to_datetime(base_date_str)
    df = demand_df.copy()
    df["date"] = pd.to_datetime(df["date"])
    # í•„í„°: ê¸°ì¤€ì¼ ì´ì „ lookback_days êµ¬ê°„
    start = latest - pd.Timedelta(days=lookback_days)
    df = df[(df["date"] > start) & (df["date"] <= latest)]
    # ì¹´í…Œê³ ë¦¬Â·SKU í•„í„°
    sku_filtered = sku_df.copy()
    if cat != "ALL":
        sku_filtered = sku_filtered[sku_filtered["category"] == cat]
    if sku_pick != "ALL":
        sku_filtered = sku_filtered[sku_filtered["sku"] == sku_pick]
    sku_list = sku_filtered["sku"].unique().tolist()
    if not sku_list:
        return pd.DataFrame(columns=["date", "sku", "forecast_qty"])
    df = df[df["sku"].isin(sku_list)]
    if df.empty:
        return pd.DataFrame(columns=["date", "sku", "forecast_qty"])
    rows = []
    for sku_code, g in df.groupby("sku"):
        g = g.sort_values("date")
        hist_window = g[g["date"] > latest - pd.Timedelta(days=window_days)]
        if hist_window.empty:
            continue
        avg_val = max(0.0, hist_window["demand_qty"].mean())
        for i in range(1, horizon_days + 1):
            fd = latest + pd.Timedelta(days=i)
            rows.append({"date": fd, "sku": sku_code, "forecast_qty": avg_val})
    return pd.DataFrame(rows) if rows else pd.DataFrame(columns=["date", "sku", "forecast_qty"])


def compute_forecast_metrics(forecast_daily_df, latest_inv_df, horizon_days, base_date_str):
    """
    forecast_daily(date, sku, forecast_qty)ì™€ latest_inv(sku, onhand_qty)ë¡œ
    forecast_avg_daily, forecast_dos, stockout_date_forecast, forecast_demand_next7 ê³„ì‚°.
    """
    if forecast_daily_df is None or forecast_daily_df.empty:
        return pd.DataFrame()
    latest = pd.to_datetime(base_date_str)
    f = forecast_daily_df.copy()
    f["date"] = pd.to_datetime(f["date"])
    inv = latest_inv_df.copy()
    if inv.empty:
        return pd.DataFrame()
    if "warehouse" in inv.columns:
        inv = inv.groupby("sku")["onhand_qty"].sum().reset_index()
    agg = f.groupby("sku").agg(forecast_total=("forecast_qty", "sum")).reset_index()
    agg["forecast_avg_daily"] = (agg["forecast_total"] / float(horizon_days)).round(2)
    f7 = f[f["date"] <= latest + pd.Timedelta(days=7)]
    next7 = f7.groupby("sku")["forecast_qty"].sum().reset_index().rename(columns={"forecast_qty": "forecast_demand_next7"})
    agg = agg.merge(next7, on="sku", how="left").fillna({"forecast_demand_next7": 0})
    agg = agg.merge(inv, on="sku", how="left")
    agg["onhand_qty"] = agg["onhand_qty"].fillna(0)
    def _dos(row):
        if row["forecast_avg_daily"] and row["forecast_avg_daily"] > 0:
            return round(row["onhand_qty"] / row["forecast_avg_daily"], 1)
        return None
    agg["forecast_dos"] = agg.apply(_dos, axis=1)
    stockout_rows = []
    for sku_code, g in f.groupby("sku"):
        g = g.sort_values("date").copy()
        onhand = float(agg.loc[agg["sku"] == sku_code, "onhand_qty"].iloc[0]) if (agg["sku"] == sku_code).any() else 0.0
        g["cum"] = g["forecast_qty"].cumsum()
        over = g[g["cum"] > onhand]
        d = over["date"].iloc[0] if not over.empty else pd.NaT
        stockout_rows.append({"sku": sku_code, "stockout_date_forecast": d})
    stockout_df = pd.DataFrame(stockout_rows)
    agg = agg.merge(stockout_df, on="sku", how="left")
    return agg


def compute_mape_backtest(demand_df, base_date_str, backtest_days=14, window_days=14):
    """
    Naive backtest: ë§ˆì§€ë§‰ backtest_days ë™ì•ˆ, tì¼ì˜ ì˜ˆì¸¡ì„ ê·¸ ì´ì „ window_days í‰ê· ìœ¼ë¡œ ì¶”ì •.
    Mean Absolute Percentage Error (í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨, MAPE)ë¥¼ ë°˜í™˜.
    """
    if demand_df is None or demand_df.empty:
        return None, 0
    latest = pd.to_datetime(base_date_str)
    df = demand_df.copy()
    df["date"] = pd.to_datetime(df["date"])
    start = latest - pd.Timedelta(days=backtest_days)
    actuals = df[(df["date"] > start) & (df["date"] <= latest)]
    if actuals.empty:
        return None, 0
    errors = []
    for (sku_code, dt), g in actuals.groupby(["sku", "date"]):
        actual = g["demand_qty"].sum()
        if actual <= 0:
            continue
        hist = df[(df["sku"] == sku_code) & (df["date"] < dt) & (df["date"] >= dt - pd.Timedelta(days=window_days))]
        if hist.empty:
            continue
        pred = max(0.0, hist["demand_qty"].mean())
        ape = abs(actual - pred) / actual if actual else 0
        errors.append(ape)
    if not errors:
        return None, 0
    mape_pct = sum(errors) / len(errors) * 100.0
    return mape_pct, len(errors)


sku, demand, inv, inv_txn = load_data(_data_file_mtime())
con = duckdb.connect(database=":memory:")
con.register("sku_master", sku)
con.register("demand_daily", demand)
con.register("inventory_daily", inv)


def get_base_sku_where(cat, wh, sku_pick):
    parts = []
    if cat != "ALL":
        parts.append(f"AND m.category = '{cat}'")
    if sku_pick != "ALL":
        parts.append(f"AND m.sku = '{sku_pick}'")
    if wh != "ALL":
        parts.append(f"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '{wh}')")
    return "\n    ".join(parts) if parts else ""


def _inv_wh_where(wh):
    return f"AND warehouse = '{wh}'" if wh != "ALL" else ""


# --- ì‚¬ì´ë“œë°”: ì¡°íšŒ ì¡°ê±´ë§Œ (ì •ì±…/ì˜ˆì¸¡ì€ ê´€ë¦¬ì íƒ­ì—ì„œ) ---
st.sidebar.header("ì¡°íšŒ ì¡°ê±´")
all_dates = con.execute("SELECT DISTINCT date FROM inventory_daily ORDER BY date DESC").fetchdf()
date_opts = all_dates["date"].astype(str).tolist() if not all_dates.empty else []
default_date = date_opts[0] if date_opts else None
if not date_opts:
    st.sidebar.caption("ê¸°ì¤€ì¼ ì„ íƒì„ ìœ„í•´ ì¬ê³  ì¼ë³„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

cat_opts = ["ALL"] + sorted(sku["category"].unique().tolist())
wh_opts = ["ALL"] + sorted(inv["warehouse"].unique().tolist())
sku_opts = ["ALL"] + sorted(sku["sku"].unique().tolist())
category_map = {"ALL": "ì „ì²´", "Motor": "ëª¨í„°", "Brake": "ë¸Œë ˆì´í¬", "Steering": "ìŠ¤í‹°ì–´ë§", "Sensor": "ì„¼ì„œ"}
warehouse_map = {"ALL": "ì „ì²´", "WH-1": "ì°½ê³  1", "WH-2": "ì°½ê³  2"}

cat = st.sidebar.selectbox(
    "ì¹´í…Œê³ ë¦¬",
    options=cat_opts,
    index=0,
    format_func=lambda x: category_map.get(x, x),
    key="cat",
)
wh = st.sidebar.selectbox(
    "ì°½ê³ ",
    options=wh_opts,
    index=0,
    format_func=lambda x: warehouse_map.get(x, x),
    key="wh",
)
sku_pick = st.sidebar.selectbox(
    "SKU",
    options=sku_opts,
    index=0,
    format_func=lambda x: "ì „ì²´" if x == "ALL" else x,
    key="sku_pick",
)
if date_opts:
    date_idx = date_opts.index(st.session_state.get("base_date", default_date)) if st.session_state.get("base_date", default_date) in date_opts else 0
    base_date = st.sidebar.selectbox(
        "ê¸°ì¤€ì¼",
        options=date_opts,
        index=date_idx,
        key="base_date",
    )
else:
    base_date = None

if base_date is None:
    st.warning("ì¬ê³  ì¼ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. inventory_daily.csvë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

base_where = get_base_sku_where(cat, wh, sku_pick)
base_date_ts = pd.to_datetime(base_date)

# --- ì •ì±…Â·ì˜ˆì¸¡ ì„¤ì •: ê´€ë¦¬ì íƒ­ì—ì„œ ì„¤ì •í•œ ê°’ ì‚¬ìš© (session_state, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’) ---
lead_time_days = int(st.session_state.get("admin_lead_time_days", 7))
shortage_days = int(st.session_state.get("admin_shortage_days", 14))
over_days = int(st.session_state.get("admin_over_days", 60))
dos_basis_days = int(st.session_state.get("admin_dos_basis_days", 14))
if over_days <= shortage_days:
    over_days = shortage_days + 1
    st.session_state["admin_over_days"] = over_days
SHORTAGE_DAYS = shortage_days
OVER_DAYS = over_days
LEAD_TIME_DAYS = lead_time_days
DOS_BASIS_DAYS = dos_basis_days

MODEL_NAME = st.session_state.get("admin_forecast_model", "MovingAvg(14)")
FORECAST_HORIZON_DAYS = int(st.session_state.get("admin_forecast_horizon", 60))
FORECAST_LOOKBACK_DAYS = int(st.session_state.get("admin_forecast_lookback", 180))
# MovingAvg(N)ì—ì„œ N ì¶”ì¶œ, ì—†ìœ¼ë©´ 14
if "MovingAvg" in MODEL_NAME:
    m = re.search(r"\((\d+)\)", MODEL_NAME)
    forecast_window_days = int(m.group(1)) if m else 14
else:
    forecast_window_days = 14

# --- ì˜ˆì¸¡ ê³„ì‚° (ì˜µì…˜ B: ë‚´ë¶€ ì˜ˆì¸¡ ìœ ì§€, ì‹¤íŒ¨ ì‹œ ìë™ í´ë°± A) ---
forecast_daily = compute_forecast(
    demand_df=demand,
    sku_df=sku,
    cat=cat,
    wh=wh,
    sku_pick=sku_pick,
    base_date_str=base_date,
    horizon_days=FORECAST_HORIZON_DAYS,
    lookback_days=FORECAST_LOOKBACK_DAYS,
    window_days=forecast_window_days,
)
latest_inv_df = con.execute(
    f"""
    SELECT sku, SUM(onhand_qty) AS onhand_qty
    FROM inventory_daily
    WHERE date = '{base_date}' {_inv_wh_where(wh)}
    GROUP BY sku
    """
).fetchdf()
forecast_metrics_df = compute_forecast_metrics(forecast_daily, latest_inv_df, FORECAST_HORIZON_DAYS, base_date) if not latest_inv_df.empty else pd.DataFrame()
use_forecast = not forecast_metrics_df.empty
mape_pct, mape_n = compute_mape_backtest(demand, base_date) if use_forecast else (None, 0)
if not use_forecast:
    forecast_daily = pd.DataFrame()
    forecast_metrics_df = pd.DataFrame()


def forecast_confidence_label(mape, n):
    if mape is None or n < 10:
        return "ì •ë³´ ë¶€ì¡±"
    if mape <= 20:
        return "ë†’ìŒ"
    if mape <= 40:
        return "ë³´í†µ"
    return "ë‚®ìŒ"


forecast_confidence = forecast_confidence_label(mape_pct, mape_n) if use_forecast else "â€”"

# --- ê³µí†µ KPI/ì›ì¸/ì‹œì /ì¡°ì¹˜ìš© ë°ì´í„° (ì‹¤ì  ê¸°ë°˜ DOS) ---
kpi_sql = f"""
WITH base_sku AS (SELECT m.sku, m.category FROM sku_master m WHERE 1=1 {base_where}),
latest_inv AS (
  SELECT sku, SUM(onhand_qty) AS onhand_qty
  FROM inventory_daily
  WHERE date = '{base_date}' {_inv_wh_where(wh)}
  GROUP BY sku
),
demand_14 AS (
  SELECT sku, SUM(demand_qty) AS demand_14
  FROM demand_daily
  WHERE date > '{base_date}'::DATE - INTERVAL {DOS_BASIS_DAYS} DAY AND date <= '{base_date}'
  GROUP BY sku
),
demand_7 AS (
  SELECT COALESCE(SUM(d.demand_qty), 0) AS v
  FROM demand_daily d
  JOIN base_sku b ON d.sku = b.sku
  WHERE d.date > '{base_date}'::DATE - INTERVAL 7 DAY AND d.date <= '{base_date}'
),
sku_dos AS (
  SELECT
    b.sku,
    b.category,
    COALESCE(li.onhand_qty, 0) AS onhand_qty,
    COALESCE(d.demand_14, 0) AS demand_14,
    CASE WHEN COALESCE(d.demand_14, 0) > 0
      THEN ROUND(COALESCE(li.onhand_qty, 0) * {DOS_BASIS_DAYS} * 1.0 / NULLIF(d.demand_14, 0), 1)
      ELSE NULL END AS coverage_days
  FROM base_sku b
  LEFT JOIN latest_inv li ON b.sku = li.sku
  LEFT JOIN demand_14 d ON b.sku = d.sku
)
SELECT
  (SELECT COALESCE(SUM(onhand_qty), 0) FROM sku_dos) AS total_onhand,
  (SELECT COALESCE(v, 0) FROM demand_7) AS demand_cur_7,
  (SELECT MEDIAN(coverage_days) FROM sku_dos WHERE coverage_days IS NOT NULL) AS median_dos,
  (SELECT COUNT(*) FROM sku_dos WHERE coverage_days IS NOT NULL AND coverage_days < {SHORTAGE_DAYS}) AS stockout_sku_cnt
"""
kpi_row = con.execute(kpi_sql).fetchdf().iloc[0]
total_onhand = int(pd.to_numeric(kpi_row["total_onhand"], errors="coerce")) if pd.notna(kpi_row["total_onhand"]) else 0
demand_cur_7 = int(pd.to_numeric(kpi_row["demand_cur_7"], errors="coerce")) if pd.notna(kpi_row["demand_cur_7"]) else 0
median_dos_val = kpi_row["median_dos"]
stockout_sku_cnt = int(pd.to_numeric(kpi_row["stockout_sku_cnt"], errors="coerce")) if pd.notna(kpi_row["stockout_sku_cnt"]) else 0

detail_sql = f"""
WITH base_sku AS (
  SELECT m.sku, m.sku_name, m.category
  FROM sku_master m WHERE 1=1 {base_where}
),
latest_inv AS (
  SELECT sku, warehouse, onhand_qty
  FROM inventory_daily
  WHERE date = '{base_date}' {_inv_wh_where(wh)}
),
demand_30 AS (
  SELECT sku, SUM(demand_qty) AS demand_30d
  FROM demand_daily
  WHERE date > '{base_date}'::DATE - INTERVAL 30 DAY AND date <= '{base_date}'
  GROUP BY sku
),
demand_14 AS (
  SELECT sku, SUM(demand_qty) AS demand_14
  FROM demand_daily
  WHERE date > '{base_date}'::DATE - INTERVAL {DOS_BASIS_DAYS} DAY AND date <= '{base_date}'
  GROUP BY sku
),
demand_7d AS (
  SELECT sku, SUM(demand_qty) AS demand_7d
  FROM demand_daily
  WHERE date > '{base_date}'::DATE - INTERVAL 7 DAY AND date <= '{base_date}'
  GROUP BY sku
)
SELECT
  b.sku, b.sku_name, b.category, li.warehouse,
  COALESCE(li.onhand_qty, 0) AS onhand_qty,
  COALESCE(d30.demand_30d, 0) AS demand_30d,
  COALESCE(d7.demand_7d, 0) AS demand_7d,
  CASE WHEN COALESCE(d14.demand_14, 0) > 0
    THEN ROUND(COALESCE(li.onhand_qty, 0) * {DOS_BASIS_DAYS} * 1.0 / NULLIF(d14.demand_14, 0), 1)
    ELSE NULL END AS coverage_days,
  CASE WHEN COALESCE(d14.demand_14, 0) > 0
    THEN date_add('{base_date}'::DATE, CAST(CEIL(COALESCE(li.onhand_qty, 0) * {DOS_BASIS_DAYS} * 1.0 / NULLIF(d14.demand_14, 0)) AS INTEGER))
    ELSE NULL END AS estimated_stockout_date
FROM base_sku b
LEFT JOIN latest_inv li ON b.sku = li.sku
LEFT JOIN demand_30 d30 ON b.sku = d30.sku
LEFT JOIN demand_14 d14 ON b.sku = d14.sku
LEFT JOIN demand_7d d7 ON b.sku = d7.sku
"""
base_df = con.execute(detail_sql).fetchdf()

# --- (A) base_df ìƒì„± ì§í›„: ì˜ˆì¸¡ merge ë° dos_used/est_date_used/demand7_used ìƒì„± ---
if base_df.empty:
    # ë¹ˆ ê²½ìš°ì—ë„ ì•„ë˜ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ë„ë¡ ë¯¸ë¦¬ ìƒì„±
    base_df["dos_used"] = pd.Series(dtype="float")
    base_df["est_date_used"] = pd.Series(dtype="datetime64[ns]")
    base_df["demand7_used"] = pd.Series(dtype="float")
else:
    if use_forecast and not forecast_metrics_df.empty:
        fm = forecast_metrics_df[["sku", "forecast_dos", "stockout_date_forecast", "forecast_demand_next7"]].drop_duplicates("sku")
        base_df = base_df.merge(fm, on="sku", how="left")
        base_df["dos_used"] = base_df.apply(
            lambda r: r["forecast_dos"] if pd.notna(r.get("forecast_dos")) else r["coverage_days"],
            axis=1,
        )
        base_df["est_date_used"] = base_df.apply(
            lambda r: r["stockout_date_forecast"] if pd.notna(r.get("stockout_date_forecast")) else r["estimated_stockout_date"],
            axis=1,
        )
        base_df["demand7_used"] = base_df.apply(
            lambda r: r["forecast_demand_next7"] if pd.notna(r.get("forecast_demand_next7")) else r["demand_7d"],
            axis=1,
        )
    else:
        base_df["dos_used"] = base_df["coverage_days"]
        base_df["est_date_used"] = base_df["estimated_stockout_date"]
        base_df["demand7_used"] = base_df["demand_7d"]


# --- (C) ìƒíƒœ ì»¬ëŸ¼(ìƒíƒœ/_mark) í•œ ë²ˆë§Œ ìƒì„± ---
def classify_status(est_date, dos):
    # 1) DOSê°€ ìˆìœ¼ë©´ DOSë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ìƒíƒœ ê²°ì • (ìš´ì˜ ê´€ì ì—ì„œ ê°€ì¥ ì•ˆì •ì )
    if pd.notna(dos):
        if dos < LEAD_TIME_DAYS:
            return "ğŸ”´", "ê¸´ê¸‰"
        if dos < SHORTAGE_DAYS:
            return "ğŸŸ ", "ì£¼ì˜"
        return "ğŸŸ¢", "ì•ˆì •"

    # 2) DOSê°€ ì—†ìœ¼ë©´(ìˆ˜ìš” 0 ë“±) ë‚ ì§œë¡œ ë³´ì¡° íŒë‹¨
    est = pd.to_datetime(est_date, errors="coerce")
    if pd.isna(est):
        # ìˆ˜ìš”ê°€ ì—†ì–´ DOSë„/í’ˆì ˆì¼ë„ ì‚°ì¶œ ë¶ˆê°€ â†’ í’ˆì ˆ ê´€ì ì€ ì•ˆì •,
        # ëŒ€ì‹  Actionì—ì„œ 'ìˆ˜ìš” ì—†ìŒ + ì¬ê³  ë³´ìœ 'ë¡œ ì¡ì•„ì•¼ í•¨
        return "ğŸŸ¢", "ì•ˆì •"

    if est < base_date_ts + pd.Timedelta(days=LEAD_TIME_DAYS):
        return "ğŸ”´", "ê¸´ê¸‰"
    if est < base_date_ts + pd.Timedelta(days=SHORTAGE_DAYS):
        return "ğŸŸ ", "ì£¼ì˜"
    return "ğŸŸ¢", "ì•ˆì •"

if base_df.empty:
    base_df["_mark"] = pd.Series(dtype="object")
    base_df["ìƒíƒœ"] = pd.Series(dtype="object")
else:
    marks, labels = zip(*[
        classify_status(r.get("est_date_used"), r.get("dos_used"))
        for _, r in base_df.iterrows()
    ])
    base_df["_mark"] = list(marks)
    base_df["ìƒíƒœ"] = list(labels)

base_df["priority_score"] = base_df.apply(
    lambda r: (r.get("demand7_used") or 0) / max((r.get("dos_used") or 1), 1),
    axis=1,
)


# --- ìƒë‹¨ í—¤ë”: ì™¼ìª½ íƒ€ì´í‹€ + ì˜¤ë¥¸ìª½ ìƒë‹¨ ì •ì±…/ì˜ˆì¸¡ ë°•ìŠ¤ 2ê°œ ---
col_title, col_boxes = st.columns([2, 1])
with col_title:
    st.title("ì¬ê³ Â·ìˆ˜ìš” ìš´ì˜ ëŒ€ì‹œë³´ë“œ")
with col_boxes:
    policy_text = (
        f"ğŸ”´ ê¸´ê¸‰: DOS < LT({LEAD_TIME_DAYS}ì¼) | "
        f"ğŸŸ  ì£¼ì˜: LT({LEAD_TIME_DAYS}ì¼) â‰¤ DOS < {SHORTAGE_DAYS}ì¼ | "
        f"ğŸŸ¢ ì•ˆì •: {SHORTAGE_DAYS}ì¼ â‰¤ DOS | "
        f"ğŸ”µ ê³¼ë‹¤: DOS > {OVER_DAYS}ì¼"
    )
    policy_html = f'<div class="header-info-box"><div class="label">ğŸ”§ ì •ì±… ê¸°ì¤€</div><div class="value">{policy_text}</div></div>'
    st.markdown(policy_html, unsafe_allow_html=True)
    if use_forecast:
        forecast_text = f"{MODEL_NAME} Â· í•™ìŠµ {FORECAST_LOOKBACK_DAYS}ì¼ Â· ì˜ˆì¸¡ {FORECAST_HORIZON_DAYS}ì¼ Â· ì‹ ë¢°ë„ {forecast_confidence}"
        forecast_html = f'<div class="header-info-box"><div class="label">ğŸ“ˆ ì˜ˆì¸¡ ì‚¬ìš©</div><div class="value">{forecast_text}</div></div>'
    else:
        forecast_text = "ì‹¤ì  ê¸°ë°˜ â€” Days of Supply (ì¬ê³  ì»¤ë²„ ì¼ìˆ˜, DOS)ë§Œ ì‚¬ìš©"
        forecast_html = f'<div class="header-info-box"><div class="label">ğŸ“ˆ ì˜ˆì¸¡</div><div class="value">{forecast_text}</div></div>'
    st.markdown(forecast_html, unsafe_allow_html=True)

tab_overview, tab_cause, tab_time, tab_action, tab_admin = st.tabs([
    "Overview",
    "ì¬ê³  ìœ„í—˜ SKU ë¶„ì„",
    "í’ˆì ˆ ë°œìƒ SKU ë¶„ì„",
    "ê¶Œì¥ ë°œì£¼Â·ì¬ê³  ë¶„ì„",
    "ê´€ë¦¬ì í˜ì´ì§€(Optional)",
])

# ========== 1) Overview (ìš”ì•½) â€” 1) ì§€ê¸ˆ ì¬ê³  ìƒíƒœëŠ” ì•ˆì „í•œê°€? ==========
with tab_overview:
    # íƒ­ ìƒë‹¨ ìƒíƒœ ë°°ì§€ + í•µì‹¬ í•œ ë¬¸ì¥
    worst_state = "ì•ˆì •"
    worst_state, worst_mark = "ì•ˆì •", "ğŸŸ¢"
    if not base_df.empty:
        if (base_df["ìƒíƒœ"] == "ê¸´ê¸‰").any():
            worst_state, worst_mark = "ê¸´ê¸‰", "ğŸ”´"
        elif (base_df["ìƒíƒœ"] == "ì£¼ì˜").any():
            worst_state, worst_mark = "ì£¼ì˜", "ğŸŸ "

    risk_cnt = int((base_df["dos_used"].notna() & (base_df["dos_used"] < SHORTAGE_DAYS)).sum()) if not base_df.empty else 0
    st.markdown(f"{worst_mark} í˜„ì¬ ì¬ê³  ìƒíƒœ: {worst_state} Â· í’ˆì ˆ ìœ„í—˜ SKU {risk_cnt}ê±´")


    median_dos_str = f"{median_dos_val:,.1f}ì¼" if pd.notna(median_dos_val) and median_dos_val == median_dos_val else "â€”"

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì „ì²´ ì¬ê³  ìˆ˜ëŸ‰", fmt_qty(total_onhand))
    c1.caption("í˜„ì¬ ê¸°ì¤€ ì¬ê³  ìˆ˜ëŸ‰")
    c2.metric("ìµœê·¼ 7ì¼ ìˆ˜ìš” í•©ê³„", fmt_qty(demand_cur_7))
    c3.metric("Days of Supply(ì¬ê³ ì»¤ë²„ì¼ìˆ˜, DOS) ì¤‘ì•™ê°’", median_dos_str)
    if pd.notna(median_dos_val) and median_dos_val == median_dos_val:
        _cmp = "ì •ì±… ê¸°ì¤€(" + str(SHORTAGE_DAYS) + "ì¼) ëŒ€ë¹„ ì—¬ìœ  ìˆìŒ" if median_dos_val >= SHORTAGE_DAYS else "ì •ì±… ê¸°ì¤€(" + str(SHORTAGE_DAYS) + "ì¼) ë¯¸ë§Œìœ¼ë¡œ ì£¼ì˜ í•„ìš”"
        c3.caption(f"ì •ì±… ê¸°ì¤€ ëŒ€ë¹„ {_cmp}.")
    else:
        c3.caption("DOSëŠ” í˜„ì¬ ê¸°ì¤€ ì¬ê³  ìˆ˜ëŸ‰ Ã· ì¼í‰ê·  ìˆ˜ìš”ë¡œ ì‚°ì¶œ")
    c4.metric("í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜", fmt_qty(stockout_sku_cnt))
    c4.caption(f"ì •ì±… ê¸°ì¤€ {SHORTAGE_DAYS}ì¼ ì´ë‚´ ì†Œì§„ ì˜ˆìƒ SKU ìˆ˜")

    st.divider()
    col_pie, col_bar = st.columns(2)
    with col_pie:
        st.markdown("**ì¬ê³  ìƒíƒœ ë¶„í¬**")
        if not base_df.empty:
            status_counts = base_df["ìƒíƒœ"].value_counts().rename_axis("ìƒíƒœ").reset_index(name="count")
            color_map = {"ê¸´ê¸‰": "#e11d48", "ì£¼ì˜": "#f97316", "ì•ˆì •": "#22c55e"}
            fig_pie = px.pie(status_counts, names="ìƒíƒœ", values="count", color="ìƒíƒœ", color_discrete_map=color_map, hole=0.4)
            fig_pie.update_layout(showlegend=True)
            fig_pie = apply_plotly_theme(fig_pie)
            st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.caption("í‘œì‹œí•  ìƒíƒœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    with col_bar:
        if cat == "ALL" and not base_df.empty:
            st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜**")
            risk_df = base_df[base_df["ìƒíƒœ"].isin(["ê¸´ê¸‰", "ì£¼ì˜"])].copy()
            if not risk_df.empty:
                bar_df = risk_df.groupby("category")["sku"].nunique().reset_index(name="risk_sku_cnt")
                fig_bar = px.bar(bar_df, x="category", y="risk_sku_cnt", labels={"category": "ì¹´í…Œê³ ë¦¬", "risk_sku_cnt": "í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜"})
                fig_bar = apply_plotly_theme(fig_bar)
                st.plotly_chart(fig_bar, use_container_width=True)
            else:
                st.caption("í’ˆì ˆ ìœ„í—˜ SKUê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜**")
            st.caption("ì¹´í…Œê³ ë¦¬ê°€ ì „ì²´ì¼ ë•Œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

    st.divider()
    st.markdown("**ì§€ê¸ˆ ê°€ì¥ ë¨¼ì € ë´ì•¼ í•  ì´ìœ **")
    col_a, col_b, col_c = st.columns(3)
    if not base_df.empty:
        urgent_mask = base_df["ìƒíƒœ"] == "ê¸´ê¸‰"
        warn_mask = base_df["ìƒíƒœ"] == "ì£¼ì˜"
        high_demand = base_df["demand_30d"] >= base_df["demand_30d"].quantile(0.75)
        low_dos = base_df["dos_used"].notna() & (base_df["dos_used"] < SHORTAGE_DAYS)
        high_demand_low_dos = (high_demand & low_dos)
        n_urgent = int(urgent_mask.sum())
        n_warn = int(warn_mask.sum())
        n_hdld = int(high_demand_low_dos.sum())
    else:
        n_urgent = n_warn = n_hdld = 0
    col_a.markdown(f"ğŸ”´ LT ì´ì „ í’ˆì ˆ {n_urgent}ê±´")
    col_b.markdown(f"ğŸŸ  14ì¼ ì´ë‚´ ì†Œì§„ {n_warn}ê±´")
    col_c.markdown(f"âš  ìˆ˜ìš” ê¸‰ì¦ ëŒ€ë¹„ ì¬ê³  ë¶€ì¡± {n_hdld}ê±´")

# ========== 2) ì¬ê³  ìœ„í—˜ ì›ì¸ ë¶„ì„ (Cause) â€” 2) ì–´ë–¤ SKUê°€ ë¬¸ì œì¸ê°€, ì™œ? ==========
with tab_cause:
    worst_state = "ì•ˆì •"
    worst_mark = "ğŸŸ¢"
    if not base_df.empty:
        if (base_df["ìƒíƒœ"] == "ê¸´ê¸‰").any():
            worst_state, worst_mark = "ê¸´ê¸‰", "ğŸ”´"
        elif (base_df["ìƒíƒœ"] == "ì£¼ì˜").any():
            worst_state, worst_mark = "ì£¼ì˜", "ğŸŸ "
    st.markdown(f"{worst_mark} ë¬¸ì œ SKUì™€ ì›ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")

    health = base_df.copy()
    health_with_dos = health[health["dos_used"].notna()].copy()

    col_cards, col_chart = st.columns([1, 2])
    with col_cards:
        if not health_with_dos.empty:
            demand_p75 = float(health_with_dos["demand_30d"].quantile(0.75))
            demand_p25 = float(health_with_dos["demand_30d"].quantile(0.25))
            cond_high_short = (health_with_dos["demand_30d"] >= demand_p75) & (health_with_dos["dos_used"] < SHORTAGE_DAYS)
            cond_low_long = (health_with_dos["demand_30d"] <= demand_p25) & (health_with_dos["dos_used"] > OVER_DAYS)
            cond_zero_with_stock = (health_with_dos["demand_30d"] == 0) & (health_with_dos["onhand_qty"] > 0)
            st.metric("ìˆ˜ìš” ë†’ìŒ + DOS ì§§ìŒ", f"{int(cond_high_short.sum()):,}ê±´")
            st.metric("ìˆ˜ìš” ë‚®ìŒ + DOS ê¹€", f"{int(cond_low_long.sum()):,}ê±´")
            st.metric("ìµœê·¼ ìˆ˜ìš” 0 + ì¬ê³  ë³´ìœ ", f"{int(cond_zero_with_stock.sum()):,}ê±´")
        else:
            st.caption("ì›ì¸ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    with col_chart:
        if not health_with_dos.empty:
            demand_p75 = float(health_with_dos["demand_30d"].quantile(0.75))
            fig = px.scatter(
                health_with_dos,
                x="demand_30d",
                y="dos_used",
                size="demand_30d",
                color="ìƒíƒœ",
                color_discrete_map={"ê¸´ê¸‰": "#e11d48", "ì£¼ì˜": "#f97316", "ì•ˆì •": "#22c55e"},
                hover_data=["sku", "sku_name", "onhand_qty", "demand_30d", "dos_used"],
                title="ìˆ˜ìš” Ã— ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS) ë§¤íŠ¸ë¦­ìŠ¤",
            )
            fig.update_layout(xaxis_title="ìµœê·¼ 30ì¼ ìˆ˜ìš”(ê°œ)", yaxis_title="ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)")
            add_ref_hline(fig, SHORTAGE_DAYS, f"í’ˆì ˆ ìœ„í—˜ ê¸°ì¤€({SHORTAGE_DAYS}ì¼)", line_color="crimson")
            add_ref_hline(fig, OVER_DAYS, f"ì¬ê³  ê³¼ë‹¤ ê²€í†  ê¸°ì¤€({OVER_DAYS}ì¼)", line_color="steelblue")
            add_ref_vline(fig, demand_p75, "ìˆ˜ìš” ìƒìœ„ 25%", line_color="gray")
            fig = apply_plotly_theme(fig)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("**[SKU ë¶„ì„] ì¬ê³  ì»¤ë²„ ì¼ìˆ˜ê°€ ì •ì±… ê¸°ì¤€ë³´ë‹¤ ì§§ê³ , ìˆ˜ìš” ì˜í–¥ë„ê°€ ë†’ì•„ ìš°ì„  ì ê²€ í•„ìš”**")
    short_high = health_with_dos[(health_with_dos["dos_used"] < SHORTAGE_DAYS) & (health_with_dos["demand_30d"] > 0)].copy()
    if not short_high.empty:
        demand_p75_val = short_high["demand_30d"].quantile(0.75)
        short_high = short_high[short_high["demand_30d"] >= demand_p75_val].sort_values("dos_used", ascending=True)
        disp = short_high[["sku", "sku_name", "warehouse", "onhand_qty", "demand_30d", "dos_used", "_mark", "ìƒíƒœ"]].copy()
        disp["onhand_qty"] = disp["onhand_qty"].apply(fmt_qty)
        disp["demand_30d"] = disp["demand_30d"].apply(fmt_qty)
        disp["dos_used"] = disp["dos_used"].apply(lambda x: fmt_days(x) + "ì¼" if pd.notna(x) else "â€”")
        disp = disp.rename(columns={
            "sku": "SKU",
            "sku_name": "í’ˆëª©ëª…",
            "warehouse": "ì°½ê³ ",
            "onhand_qty": "í˜„ì¬ê³ (ê°œ)",
            "demand_30d": "ìµœê·¼ 30ì¼ ìˆ˜ìš”(ê°œ)",
            "dos_used": "ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)",
            "_mark": "ìƒíƒœ ë§ˆí¬",
        })
        st.dataframe(disp, use_container_width=True, hide_index=True)
    else:
        st.caption("í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” SKUê°€ ì—†ìŠµë‹ˆë‹¤.")

# ========== 3) í’ˆì ˆ ë°œìƒ ì‹œì  ë¶„ì„ (Time) â€” 3) ì–¸ì œ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ê°€? ==========
with tab_time:
    worst_state = "ì•ˆì •"
    worst_mark = "ğŸŸ¢"
    if not base_df.empty:
        if (base_df["ìƒíƒœ"] == "ê¸´ê¸‰").any():
            worst_state, worst_mark = "ê¸´ê¸‰", "ğŸ”´"
        elif (base_df["ìƒíƒœ"] == "ì£¼ì˜").any():
            worst_state, worst_mark = "ì£¼ì˜", "ğŸŸ "
    st.markdown(f"{worst_mark} ì–¸ì œ í’ˆì ˆì´ ë°œìƒí•˜ëŠ”ì§€ íƒ€ì„ë¼ì¸ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.")

    time_df = base_df.copy()
    time_df["est_date_used"] = pd.to_datetime(time_df["est_date_used"], errors="coerce")

    st.markdown("**[SKU ë¶„ì„] ì˜ˆìƒ í’ˆì ˆ íƒ€ì„ë¼ì¸**" + (" (ì˜ˆì¸¡)" if use_forecast else " (ì‹¤ì  ê¸°ë°˜)"))
    if not time_df.empty and time_df["est_date_used"].notna().any():
        tl = time_df[time_df["est_date_used"].notna()].copy()
        tl["date"] = tl["est_date_used"]
        tl["count"] = 1
        fig_t = px.scatter(
            tl,
            x="date",
            y="sku",
            color="ìƒíƒœ",
            color_discrete_map={"ê¸´ê¸‰": "#e11d48", "ì£¼ì˜": "#f97316", "ì•ˆì •": "#22c55e"},
            hover_data=["sku", "sku_name", "warehouse", "dos_used"]
        )
        fig_t.update_layout(xaxis_title="ì˜ˆìƒ í’ˆì ˆì¼", yaxis_title="SKU")
        fig_t = apply_plotly_theme(fig_t)
        st.plotly_chart(fig_t, use_container_width=True)
    else:
        st.caption("ì˜ˆìƒ í’ˆì ˆì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("**[SKU ë¶„ì„] ì˜ˆìƒ í’ˆì ˆì¼Â·DOSÂ·ë¦¬ë“œíƒ€ì„ ëŒ€ë¹„ ìƒíƒœ í™•ì¸**" + (" (ì˜ˆì¸¡)" if use_forecast else " (ì‹¤ì  ê¸°ë°˜)"))
    show_time = time_df[time_df["dos_used"].notna()].copy()
    show_time = show_time.sort_values(["ìƒíƒœ", "est_date_used"], ascending=[True, True])
    if not show_time.empty:
        disp_t = show_time[["sku", "sku_name", "warehouse", "est_date_used", "dos_used", "_mark", "ìƒíƒœ"]].copy()
        disp_t["ì˜ˆìƒ í’ˆì ˆì¼"] = disp_t["est_date_used"].apply(fmt_date)
        disp_t["ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)"] = disp_t["dos_used"].apply(lambda x: fmt_days(x) + "ì¼" if pd.notna(x) else "â€”")
        disp_t = disp_t.rename(columns={
            "sku": "SKU",
            "sku_name": "í’ˆëª©ëª…",
            "warehouse": "ì°½ê³ ",
            "_mark": "ìƒíƒœ ë§ˆí¬",
        })
        # ê¸´ê¸‰ì´ ìœ„ë¡œ ì˜¤ë„ë¡ ìƒíƒœ ìˆœì„œ ì •ë ¬
        state_order = {"ê¸´ê¸‰": 0, "ì£¼ì˜": 1, "ì•ˆì •": 2}
        disp_t["_order"] = disp_t["ìƒíƒœ"].map(state_order)
        disp_t = disp_t.sort_values(["_order", "ì˜ˆìƒ í’ˆì ˆì¼"])
        disp_t = disp_t.drop(columns=["_order"])
        st.dataframe(disp_t, use_container_width=True, hide_index=True)
    else:
        st.caption("DOSê°€ ì‚°ì¶œëœ SKUê°€ ì—†ìŠµë‹ˆë‹¤.")

# ========== 4) ê¶Œì¥ ë°œì£¼Â·ì¬ê³  ì¡°ì • (Action) â€” 4) ë¬´ì—‡ì„ ì¡°ì¹˜í•´ì•¼ í•˜ëŠ”ê°€? ==========
with tab_action:
    worst_state = "ì•ˆì •"
    worst_mark = "ğŸŸ¢"
    if not base_df.empty:
        if (base_df["ìƒíƒœ"] == "ê¸´ê¸‰").any():
            worst_state, worst_mark = "ê¸´ê¸‰", "ğŸ”´"
        elif (base_df["ìƒíƒœ"] == "ì£¼ì˜").any():
            worst_state, worst_mark = "ì£¼ì˜", "ğŸŸ "
    st.markdown(f"{worst_mark} ì§€ê¸ˆ ë°œì£¼Â·ì¬ê³  ì¡°ì •ì´ í•„ìš”í•œ SKUë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("**ì¦‰ì‹œ ë°œì£¼ ë˜ëŠ” ì¬ê³  ì¡°ì • ê²€í† ê°€ í•„ìš”í•œ SKU**" + (" (ì˜ˆì¸¡ ê¸°ë°˜)" if use_forecast else " (ì‹¤ì  ê¸°ë°˜)"))
    st.caption("ì´ í…Œì´ë¸”ì€ ì™œ ì¡°ì¹˜í•´ì•¼ í•˜ëŠ”ì§€, ì¡°ì¹˜í•˜ì§€ ì•Šì„ ê²½ìš° ë¦¬ìŠ¤í¬, ê¶Œì¥ ì¡°ì¹˜ë¥¼ í•œ ë²ˆì— ë³´ì—¬ì¤ë‹ˆë‹¤.")

    action_list = []
    if not base_df.empty:
        demand_p25 = float(base_df["demand_30d"].quantile(0.25)) if not base_df["demand_30d"].empty else 0
        for _, row in base_df.iterrows():
            cov = row.get("dos_used")
            onhand = int(row.get("onhand_qty", 0) or 0)
            d30 = float(row.get("demand_30d", 0) or 0)
            state_mark = row.get("_mark", "ğŸŸ¢")
            state_label = row.get("ìƒíƒœ", "ì•ˆì •")

            reason = risk = action = None
            if pd.notna(cov) and cov < SHORTAGE_DAYS and d30 > 0:
                reason = f"ì¬ê³  ì»¤ë²„ ì¼ìˆ˜ê°€ ì •ì±… ê¸°ì¤€({SHORTAGE_DAYS}ì¼)ë³´ë‹¤ ì§§ìŒ(í˜„ì¬ {fmt_days(cov)}ì¼)."
                risk = "ë°œì£¼ ì§€ì—° ì‹œ í’ˆì ˆë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒ."
                action = "ë°œì£¼"
            elif pd.notna(cov) and cov > OVER_DAYS and d30 <= demand_p25:
                reason = f"ì¬ê³  ì»¤ë²„ ì¼ìˆ˜ê°€ {OVER_DAYS}ì¼ì„ ì´ˆê³¼í•˜ê³  ìµœê·¼ ìˆ˜ìš”ê°€ ë‚®ìŒ."
                risk = "ì¬ê³  ìœ ì§€ ë¹„ìš©Â·íê¸° ë¦¬ìŠ¤í¬ ì¦ê°€."
                action = "ì¬ê³  ê°ì¶•"
            elif d30 == 0 and onhand > 0:
                reason = "ìµœê·¼ 30ì¼ ìˆ˜ìš”ê°€ ì—†ëŠ” SKUë¡œ ì¬ê³ ë§Œ ë³´ìœ ."
                risk = "ì¬ê³  ë¶€íŒ¨Â·íê¸° ê°€ëŠ¥ì„±."
                action = "ì¬ê³  ì¡°ì • ê²€í† "
            else:
                continue
            action_list.append({
                "ìƒíƒœ ë§ˆí¬": state_mark,
                "SKU": row["sku"],
                "í’ˆëª©ëª…": row.get("sku_name", ""),
                "ì°½ê³ ": row.get("warehouse", "â€”"),
                "ì™œ ì¡°ì¹˜í•´ì•¼ í•˜ëŠ”ê°€(ì‚¬ìœ )": reason,
                "ì¡°ì¹˜í•˜ì§€ ì•Šì„ ê²½ìš° ë¦¬ìŠ¤í¬": risk,
                "ê¶Œì¥ ì¡°ì¹˜": action,
                "ìš°ì„ ìˆœìœ„ ì ìˆ˜": row.get("priority_score", 0.0),
            })

    action_df = pd.DataFrame(action_list)
    if not action_df.empty:
        action_df = action_df.sort_values("ìš°ì„ ìˆœìœ„ ì ìˆ˜", ascending=False)
        st.dataframe(action_df, use_container_width=True, hide_index=True)
    else:
        st.caption("ì¦‰ì‹œ ë°œì£¼ ë˜ëŠ” ì¬ê³  ì¡°ì •ì´ í•„ìš”í•œ SKUê°€ ì—†ìŠµë‹ˆë‹¤.")

# ========== 5) ê´€ë¦¬ì â€” ì •ì±… ì„¤ì • + ì˜ˆì¸¡ ëª¨ë¸ ì„¤ì • ==========
with tab_admin:
    st.subheader("ì •ì±… ì„¤ì •")
    st.caption("ë¦¬ë“œíƒ€ì„Â·í’ˆì ˆ ìœ„í—˜Â·ì¬ê³  ê³¼ë‹¤ ê¸°ì¤€ê³¼ DOS ì‚°ì • ê¸°ê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ë³€ê²½ í›„ ë‹¤ë¥¸ íƒ­ì—ì„œ ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
    p1, p2, p3, p4 = st.columns(4)
    with p1:
        st.number_input("ë¦¬ë“œíƒ€ì„ LT (ì¼)", min_value=1, value=st.session_state.get("admin_lead_time_days", 7), key="admin_lead_time_days", step=1)
    with p2:
        st.number_input("í’ˆì ˆ ìœ„í—˜ ê¸°ì¤€ DOS (ì¼)", min_value=1, value=st.session_state.get("admin_shortage_days", 14), key="admin_shortage_days", step=1)
    with p3:
        st.number_input("ì¬ê³  ê³¼ë‹¤ ê¸°ì¤€ DOS (ì¼)", min_value=1, value=st.session_state.get("admin_over_days", 60), key="admin_over_days", step=1)
    with p4:
        st.number_input("DOS ì‚°ì • ê¸°ê°„ (ìµœê·¼ Nì¼)", min_value=1, value=st.session_state.get("admin_dos_basis_days", 14), key="admin_dos_basis_days", step=1)
    if st.session_state.get("admin_over_days", 60) <= st.session_state.get("admin_shortage_days", 14):
        st.warning("ì¬ê³  ê³¼ë‹¤ ê¸°ì¤€ì´ í’ˆì ˆ ìœ„í—˜ ê¸°ì¤€ ì´í•˜ì…ë‹ˆë‹¤. ì €ì¥ ì‹œ ìë™ ë³´ì •(ê³¼ë‹¤ = í’ˆì ˆìœ„í—˜+1)ë©ë‹ˆë‹¤.")
    st.divider()
    st.subheader("ì˜ˆì¸¡ ëª¨ë¸ ì„¤ì •")
    st.caption("ìˆ˜ìš” ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸Â·í•™ìŠµì¼Â·ì˜ˆì¸¡ì¼ì„ ì„¤ì •í•©ë‹ˆë‹¤. ë³€ê²½ í›„ ë‹¤ë¥¸ íƒ­ì—ì„œ ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
    model_opts = ["MovingAvg(7)", "MovingAvg(14)", "MovingAvg(30)", "SeasonalNaive(7)"]
    idx = model_opts.index(st.session_state.get("admin_forecast_model", "MovingAvg(14)")) if st.session_state.get("admin_forecast_model", "MovingAvg(14)") in model_opts else 1
    f1, f2, f3, f4 = st.columns(4)
    with f1:
        st.selectbox(
            "ì˜ˆì¸¡ ëª¨ë¸",
            options=model_opts,
            index=idx,
            key="admin_forecast_model",
            help="MovingAvg(N): ìµœê·¼ Nì¼ ìˆ˜ìš” í‰ê· . SeasonalNaive(7): ìµœê·¼ 7ì¼ íŒ¨í„´ ë°˜ë³µ.",
        )
    with f2:
        st.number_input("í•™ìŠµ êµ¬ê°„ (ì¼)", min_value=30, value=st.session_state.get("admin_forecast_lookback", 180), key="admin_forecast_lookback", step=1)
    with f3:
        st.number_input("ì˜ˆì¸¡ ê¸°ê°„ (ì¼)", min_value=7, value=st.session_state.get("admin_forecast_horizon", 60), key="admin_forecast_horizon", step=1)
    with f4:
        st.caption("**í˜„ì¬ ì ìš©**  \nëª¨ë¸: " + st.session_state.get("admin_forecast_model", "MovingAvg(14)") + "  \ní•™ìŠµ " + str(st.session_state.get("admin_forecast_lookback", 180)) + "ì¼ Â· ì˜ˆì¸¡ " + str(st.session_state.get("admin_forecast_horizon", 60)) + "ì¼")
