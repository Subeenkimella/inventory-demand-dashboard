import math
import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px

st.set_page_config(page_title="ì¬ê³ Â·ìˆ˜ìš” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", layout="wide", initial_sidebar_state="expanded")

# [ë¬¸êµ¬ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ]
# 1. í†¤: í˜„ì—…(êµ¬ë§¤/ìì¬/SCM)ì´ 5ì´ˆ ì•ˆì— ìƒíƒœÂ·ë¦¬ìŠ¤í¬Â·ì¡°ì¹˜ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì§§ê³  ë‹¨ì •í•˜ê²Œ(í•œ ë¬¸ì¥ 25~60ì).
# 2. ìš©ì–´: ì˜ì–´ í˜¼ìš© ê¸ˆì§€. MAPEÂ·SKUÂ·DOS ë“± ì—…ê³„ ì•½ì–´ëŠ” ê´„í˜¸ë¡œ 1íšŒë§Œ í’€ì–´ì„œ ë³‘ê¸° í›„ ì´í›„ ì•½ì–´ë§Œ ì‚¬ìš©.
# 3. ì§€í‘œ: DOS ì²« ë“±ì¥ ì‹œ "DOS(ì¬ê³  ì»¤ë²„ë¦¬ì§€ ì¼ìˆ˜) = ì¬ê³  Ã· ì¼í‰ê·  ìˆ˜ìš”" í’€ì´. ê¸°ì¤€ì„ (ë¶€ì¡±/ê³¼ì‰)ì€ ìº¡ì…˜ì— ëª…ì‹œ.
# 4. êµ¬ë¶„: ì‹¤ì  ê¸°ì¤€ / ì˜ˆì¸¡ ê¸°ì¤€ìœ¼ë¡œ í‘œê¸°. ê²½ê³ ëŠ” "ì›ì¸â†’ì˜í–¥â†’í™•ì¸í•  ê²ƒ" ìˆœ 1~2ë¬¸ì¥.
# 5. ë‹¨ìœ„: ìˆ˜ëŸ‰ì€ ì½¤ë§ˆ ì •ìˆ˜, ë¹„ìœ¨ì€ % ì†Œìˆ˜ 1ìë¦¬, ì¼ìˆ˜ëŠ” ì†Œìˆ˜ 1ìë¦¬, ì¼ìëŠ” YYYY-MM-DD.

def apply_plotly_theme(fig):
    fig.update_layout(
        template="plotly_white",
        font=dict(size=13),
        title_font=dict(size=16),
        legend_font=dict(size=12),
        xaxis=dict(showgrid=True, gridcolor="#e5e5e5"),
        yaxis=dict(
            showgrid=True,
            gridcolor="#e5e5e5",
            tickformat=",.0f",
        ),
        margin=dict(l=40, r=20, t=60, b=40),
    )
    return fig


# Plotly add_vline/add_hline(..., annotation_text=...) can raise TypeError when x/y is a
# pandas Timestamp (Plotly internally tries sum([Timestamp]) for annotation position).
# Use separate add_vline/add_hline (no annotation_text) plus add_annotation for labels.

def to_plotly_x(value):
    """Convert pandas Timestamp/date/string to a value safe for Plotly (datetime or string). Numerics passed through."""
    if value is None:
        return None
    if isinstance(value, (int, float)) and not isinstance(value, bool):
        return value
    try:
        return pd.to_datetime(value).to_pydatetime()
    except Exception:
        return str(value)


def add_ref_vline(fig, x, label="ê¸°ì¤€ì¼", line_dash="dot", line_color="gray"):
    """Draw a vertical reference line and a separate text annotation (avoids annotation_text Timestamp bug)."""
    x0 = to_plotly_x(x)
    fig.add_vline(x=x0, line_dash=line_dash, line_color=line_color)
    fig.add_annotation(
        x=x0, y=1, xref="x", yref="paper",
        text=label, showarrow=False,
        yanchor="bottom", xanchor="left",
    )
    return fig


def add_ref_hline(fig, y, label, line_dash="dot", line_color="gray"):
    """Draw a horizontal reference line and a separate text annotation (avoids annotation_text bug)."""
    fig.add_hline(y=y, line_dash=line_dash, line_color=line_color)
    fig.add_annotation(
        x=1, y=y, xref="paper", yref="y",
        text=label, showarrow=False,
        xanchor="right", yanchor="bottom",
    )
    return fig


def add_ref_vrect(fig, x0, x1, label="", fill_color="rgba(255,165,0,0.1)", line_color="orange"):
    """Shade a period and add a separate text annotation (no annotation_text in add_vrect)."""
    x0_safe = to_plotly_x(x0)
    x1_safe = to_plotly_x(x1)
    fig.add_vrect(x0=x0_safe, x1=x1_safe, fillcolor=fill_color, line_width=0)
    if label:
        fig.add_annotation(
            x=x1_safe, y=1, xref="x", yref="paper",
            text=label, showarrow=False,
            yanchor="bottom", xanchor="left",
        )
    return fig


def fmt_qty(v):
    """Format quantity as comma-separated integer."""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return f"{int(v):,}"


def fmt_pct(v):
    """Format rate as % with 1 decimal."""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return f"{float(v):.1f}%"


def fmt_days(v):
    """Format days with 1 decimal."""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return f"{float(v):.1f}"


def fmt_date(v):
    """Format date as YYYY-MM-DD."""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return "â€”"
    return str(pd.to_datetime(v).date()) if hasattr(pd.to_datetime(v), "date") else str(v)


@st.cache_data
def load_data():
    sku = pd.read_csv("sku_master.csv")
    demand = pd.read_csv("demand_daily.csv", parse_dates=["date"])
    inv = pd.read_csv("inventory_daily.csv", parse_dates=["date"])
    try:
        inv_txn = pd.read_csv("inventory_txn.csv", parse_dates=["date", "txn_datetime"])
    except FileNotFoundError:
        inv_txn = pd.DataFrame(columns=["txn_datetime", "date", "sku", "warehouse", "txn_type", "qty", "ref_id", "reason_code"])
    return sku, demand, inv, inv_txn

sku, demand, inv, inv_txn = load_data()

# DuckDB in-memory (SQL engine)
con = duckdb.connect(database=":memory:")
con.register("sku_master", sku)
con.register("demand_daily", demand)
con.register("inventory_daily", inv)
if inv_txn is not None and len(inv_txn) > 0:
    con.register("inventory_txn", inv_txn)


def get_base_sku_where(cat, wh, sku_pick):
    """ê³µí†µ í•„í„°(cat, wh, sku_pick)ì— í•´ë‹¹í•˜ëŠ” SQL AND ì ˆ ë¬¸ìì—´. base_sku CTEì—ì„œ WHERE 1=1 ë’¤ì— ë¶™ì¸ë‹¤."""
    parts = []
    if cat != "ALL":
        parts.append(f"AND m.category = '{cat}'")
    if sku_pick != "ALL":
        parts.append(f"AND m.sku = '{sku_pick}'")
    if wh != "ALL":
        parts.append(f"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '{wh}')")
    return "\n    ".join(parts) if parts else ""


def compute_dos(onhand_qty, avg_daily_demand):
    """ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS). avg_daily_demandê°€ 0ì´ë©´ None ë°˜í™˜."""
    if avg_daily_demand is None or pd.isna(avg_daily_demand) or float(avg_daily_demand) == 0:
        return None
    o = float(onhand_qty or 0)
    return round(o / float(avg_daily_demand), 1)


def _get_filtered_skus_pandas(sku_df, inv_df, cat, wh, sku_pick):
    """ê³µí†µ í•„í„°(cat, wh, sku_pick)ì— í•´ë‹¹í•˜ëŠ” SKU ëª©ë¡. pandasë¡œ ê³„ì‚°(ìºì‹œìš©)."""
    m = sku_df.copy()
    if cat != "ALL":
        m = m[m["category"] == cat]
    if sku_pick != "ALL":
        m = m[m["sku"] == sku_pick]
    if wh != "ALL":
        wh_skus = set(inv_df[inv_df["warehouse"] == wh]["sku"].unique())
        m = m[m["sku"].isin(wh_skus)]
    return m["sku"].unique().tolist()


@st.cache_data
def compute_forecast(_demand_df, _sku_df, _inv_df, cat, wh, sku_pick, latest_date_str, horizon_days, model_type, lookback_days):
    """
    ìˆ˜ìš” ì˜ˆì¸¡: forecast_daily(date, sku, forecast_qty) ìƒì„±.
    - MovingAvg(N): ìµœê·¼ Nì¼ í‰ê· ì„ horizon_days ë™ì•ˆ ë™ì¼ ê°’ìœ¼ë¡œ ì˜ˆì¸¡.
    - SeasonalNaive(7): ìµœê·¼ 7ì¼ íŒ¨í„´ì„ horizon_daysì— ë°˜ë³µ.
    lookback_days ë²”ìœ„ ë‚´ ë°ì´í„°ë§Œ ì‚¬ìš©. ê³µí†µ í•„í„°(cat/wh/sku_pick) ì ìš© SKUë§Œ ì˜ˆì¸¡.
    """
    latest_date = pd.to_datetime(latest_date_str)
    demand = _demand_df[_demand_df["date"].notna()].copy()
    demand["date"] = pd.to_datetime(demand["date"])
    lookback_start = latest_date - pd.Timedelta(days=lookback_days)
    demand = demand[(demand["date"] >= lookback_start) & (demand["date"] <= latest_date)]

    sku_list = _get_filtered_skus_pandas(_sku_df, _inv_df, cat, wh, sku_pick)
    if not sku_list:
        return pd.DataFrame(columns=["date", "sku", "forecast_qty"])

    # model_type íŒŒì‹±: "MovingAvg(7)" -> ("MovingAvg", 7), "SeasonalNaive(7)" -> ("SeasonalNaive", 7)
    if "MovingAvg" in model_type:
        n = int(model_type.replace("MovingAvg(", "").replace(")", ""))
        method, param = "MovingAvg", n
    elif "SeasonalNaive" in model_type:
        n = int(model_type.replace("SeasonalNaive(", "").replace(")", ""))
        method, param = "SeasonalNaive", n
    else:
        method, param = "MovingAvg", 14

    rows = []
    for sku in sku_list:
        d = demand[demand["sku"] == sku].sort_values("date")
        if d.empty:
            continue
        if method == "MovingAvg":
            last_n = d.tail(param)
            if last_n.empty:
                continue
            avg_val = last_n["demand_qty"].mean()
            for i in range(1, horizon_days + 1):
                fd = latest_date + pd.Timedelta(days=i)
                rows.append({"date": fd, "sku": sku, "forecast_qty": max(0, avg_val)})
        else:  # SeasonalNaive(7)
            last_n = d.tail(param)
            if len(last_n) < param:
                avg_val = last_n["demand_qty"].mean()
                for i in range(1, horizon_days + 1):
                    fd = latest_date + pd.Timedelta(days=i)
                    rows.append({"date": fd, "sku": sku, "forecast_qty": max(0, avg_val)})
            else:
                pattern = last_n["demand_qty"].values
                for i in range(1, horizon_days + 1):
                    fd = latest_date + pd.Timedelta(days=i)
                    qty = pattern[(i - 1) % len(pattern)]
                    rows.append({"date": fd, "sku": sku, "forecast_qty": max(0, float(qty))})

    if not rows:
        return pd.DataFrame(columns=["date", "sku", "forecast_qty"])
    return pd.DataFrame(rows)


def compute_forecast_metrics(forecast_daily_df, latest_inv_df, horizon_days, latest_date):
    """
    forecast_daily(date, sku, forecast_qty)ì™€ latest_inv(sku, onhand_qty)ë¡œ
    forecast_avg_daily, forecast_dos, stockout_date_forecast, forecast_demand_next7 ê³„ì‚°.
    """
    if forecast_daily_df.empty:
        return pd.DataFrame()
    latest_date = pd.to_datetime(latest_date)
    f = forecast_daily_df.copy()
    f["date"] = pd.to_datetime(f["date"])

    inv = latest_inv_df.copy()
    if "warehouse" in inv.columns:
        inv = inv.groupby("sku")["onhand_qty"].sum().reset_index()
    else:
        inv = inv[["sku", "onhand_qty"]].drop_duplicates()

    agg = f.groupby("sku").agg(forecast_total=("forecast_qty", "sum")).reset_index()
    agg["forecast_avg_daily"] = (agg["forecast_total"] / horizon_days).round(2)
    f7 = f[f["date"] <= latest_date + pd.Timedelta(days=7)]
    next7 = f7.groupby("sku")["forecast_qty"].sum().reset_index()
    next7 = next7.rename(columns={"forecast_qty": "forecast_demand_next7"})
    agg = agg.merge(next7, on="sku", how="left").fillna(0)
    agg = agg.merge(inv, on="sku", how="left")
    agg["onhand_qty"] = agg["onhand_qty"].fillna(0)
    agg["forecast_dos"] = agg.apply(
        lambda r: round(r["onhand_qty"] / r["forecast_avg_daily"], 1) if r["forecast_avg_daily"] and r["forecast_avg_daily"] > 0 else None,
        axis=1,
    )

    # stockout_date_forecast: ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ cumsum, onhand_qty ì´ˆê³¼í•˜ëŠ” ì²« date
    stockout_list = []
    for sku in agg["sku"].unique():
        df_sku = f[f["sku"] == sku].sort_values("date")
        if df_sku.empty:
            stockout_list.append({"sku": sku, "stockout_date_forecast": None})
            continue
        onhand = float(agg.loc[agg["sku"] == sku, "onhand_qty"].iloc[0])
        df_sku = df_sku.copy()
        df_sku["cum"] = df_sku["forecast_qty"].cumsum()
        over = df_sku[df_sku["cum"] > onhand]
        d = over["date"].iloc[0] if len(over) > 0 else None
        stockout_list.append({"sku": sku, "stockout_date_forecast": d})
    stockout_df = pd.DataFrame(stockout_list)
    agg = agg.merge(stockout_df, on="sku", how="left")
    return agg


def compute_mape_backtest(demand_df, lookback_days, model_type, latest_date_str, backtest_days=14):
    """
    Naive backtest: for last `backtest_days` days, predict day t with mean of previous N days (same N as model).
    Returns aggregate MAPE % and count of (sku, date) points used.
    """
    if demand_df is None or demand_df.empty:
        return None, 0
    latest = pd.to_datetime(latest_date_str)
    if "MovingAvg" in model_type:
        n = int(model_type.replace("MovingAvg(", "").replace(")", ""))
    elif "SeasonalNaive" in model_type:
        n = int(model_type.replace("SeasonalNaive(", "").replace(")", ""))
    else:
        n = 14
    demand = demand_df.copy()
    demand["date"] = pd.to_datetime(demand["date"])
    start = latest - pd.Timedelta(days=backtest_days)
    # We need actuals in [start, latest] and history before that for prediction
    actuals = demand[(demand["date"] >= start) & (demand["date"] <= latest)]
    if actuals.empty:
        return None, 0
    errors = []
    for (sku, date), g in actuals.groupby(["sku", "date"]):
        actual = g["demand_qty"].sum()
        if actual <= 0:
            continue
        hist = demand[(demand["sku"] == sku) & (demand["date"] < date) & (demand["date"] >= date - pd.Timedelta(days=n))]
        pred = hist["demand_qty"].mean() if len(hist) > 0 else 0
        pred = max(0, pred)
        ape = abs(actual - pred) / actual if actual else 0
        errors.append(ape)
    if not errors:
        return None, 0
    mape_pct = sum(errors) / len(errors) * 100
    return mape_pct, len(errors)

st.markdown("""
<style>
    /* ì‹¤ë¬´í˜• ëŒ€ì‹œë³´ë“œ ê°€ë…ì„± */
    h1 { font-size: 1.85rem !important; font-weight: 600; margin-bottom: 0.25rem !important; }
    h2 { font-size: 1.25rem !important; font-weight: 600; margin-top: 1.25rem !important; }
    h3 { font-size: 1.05rem !important; font-weight: 600; color: #333; margin-top: 1rem !important; }
    [data-testid="stMetricValue"] { font-size: 1.5rem !important; font-weight: 600; }
    [data-testid="stMetricLabel"] { font-size: 0.9rem !important; color: #555; }
    .stCaptionContainer { font-size: 0.85rem !important; color: #666; }
    hr { margin: 1rem 0 !important; }
</style>
""", unsafe_allow_html=True)
st.title("ğŸ“¦ ì¬ê³ Â·ìˆ˜ìš” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
st.caption("ê¸°ì¤€ì¼ ê¸°ì¤€ ì¬ê³ Â·ìˆ˜ìš”Â·ì˜ˆì¸¡ì„ í•œ í™”ë©´ì—ì„œ í™•ì¸í•˜ê³ , ìƒíƒœÂ·ë¦¬ìŠ¤í¬Â·ì¡°ì¹˜ë¥¼ ë°”ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# Latest snapshot date
latest_date = con.execute("SELECT MAX(date) FROM inventory_daily").fetchone()[0]

category_map = {
  "ALL": "ì „ì²´",
  "Motor": "ëª¨í„°",
  "Brake": "ë¸Œë ˆì´í¬",
  "Steering": "ìŠ¤í‹°ì–´ë§",
  "Sensor": "ì„¼ì„œ",
}

warehouse_map = {
  "ALL" : "ì „ì²´",
  "WH-1": "ì°½ê³  1",
  "WH-2": "ì°½ê³  2",
}

plant_map = {
  "ALL": "ì „ì²´",
  "PLANT-A": "ê³µì¥ A",
  "PLANT-B": "ê³µì¥ B",
}

# --- ì‚¬ì´ë“œë°”: ì¡°íšŒ ì¡°ê±´ + ì˜ˆì¸¡ ì„¤ì • ---
st.sidebar.header("ì¡°íšŒ ì¡°ê±´")
st.sidebar.caption("ì¹´í…Œê³ ë¦¬Â·ì°½ê³ Â·SKUë¡œ ë¶„ì„ ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
cat_opts = ["ALL"] + sorted(sku["category"].unique())
wh_opts = ["ALL"] + sorted(inv["warehouse"].unique())
sku_opts = ["ALL"] + sorted(sku["sku"].unique())

st.sidebar.selectbox(
    "ì¹´í…Œê³ ë¦¬",
    options=cat_opts,
    index=cat_opts.index(st.session_state.get("cat", "ALL")) if st.session_state.get("cat", "ALL") in cat_opts else 0,
    format_func=lambda x: category_map.get(x, x),
    key="cat",
)
st.sidebar.selectbox(
    "ì°½ê³ ",
    options=wh_opts,
    index=wh_opts.index(st.session_state.get("wh", "ALL")) if st.session_state.get("wh", "ALL") in wh_opts else 0,
    format_func=lambda x: warehouse_map.get(x, x),
    key="wh",
)
st.sidebar.selectbox(
    "SKU",
    options=sku_opts,
    index=sku_opts.index(st.session_state.get("sku_pick", "ALL")) if st.session_state.get("sku_pick", "ALL") in sku_opts else 0,
    format_func=lambda x: "ì „ì²´" if x == "ALL" else x,
    key="sku_pick",
)

st.sidebar.divider()
st.sidebar.header("ì˜ˆì¸¡ ì„¤ì •")
st.sidebar.caption("ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸Â·ê¸°ê°„. OverviewÂ·ë¦¬ìŠ¤í¬Â·ë°œì£¼ íƒ­ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
horizon_opts = [7, 14, 30, 60]
model_opts = ["MovingAvg(7)", "MovingAvg(14)", "MovingAvg(30)", "SeasonalNaive(7)"]
lookback_opts = [90, 180, 365]
horizon_days = st.sidebar.selectbox(
    "ì˜ˆì¸¡ ê¸°ê°„(ì¼)",
    options=horizon_opts,
    index=horizon_opts.index(st.session_state.get("forecast_horizon_days", 14)) if st.session_state.get("forecast_horizon_days", 14) in horizon_opts else 1,
    format_func=lambda x: f"{x}ì¼",
    key="forecast_horizon_days",
)
model_type = st.sidebar.selectbox(
    "ì˜ˆì¸¡ ëª¨ë¸",
    options=model_opts,
    index=model_opts.index(st.session_state.get("forecast_model_type", "MovingAvg(14)")) if st.session_state.get("forecast_model_type", "MovingAvg(14)") in model_opts else 1,
    key="forecast_model_type",
)
lookback_days = st.sidebar.selectbox(
    "í•™ìŠµ êµ¬ê°„(ì¼)",
    options=lookback_opts,
    index=lookback_opts.index(st.session_state.get("forecast_lookback_days", 180)) if st.session_state.get("forecast_lookback_days", 180) in lookback_opts else 1,
    format_func=lambda x: f"{x}ì¼",
    key="forecast_lookback_days",
)
st.sidebar.divider()
show_only_exceptions = st.sidebar.toggle("ì˜ˆì™¸ë§Œ ë³´ê¸°", value=True, key="show_only_exceptions", help="ONì´ë©´ ë¶€ì¡±Â·ê³¼ì‰Â·í’ˆì ˆ ìœ„í—˜ í–‰ë§Œ í‘œì‹œ")
sku_search_term = st.sidebar.text_input("SKU ê²€ìƒ‰(ëª…Â·ì½”ë“œ)", value=st.session_state.get("sku_search_term", ""), key="sku_search_term", placeholder="í…Œì´ë¸”ì—ì„œ SKUë¡œ í•„í„°")
cat = st.session_state.get("cat", "ALL")
wh = st.session_state.get("wh", "ALL")
sku_pick = st.session_state.get("sku_pick", "ALL")
base_where = get_base_sku_where(cat, wh, sku_pick)

def _inv_wh_where(wh):
    return f"AND warehouse = '{wh}'" if wh != "ALL" else ""

def _inv_wh_join(wh):
    return f"AND i.warehouse = '{wh}'" if wh != "ALL" else ""


def _base_sku_cte(base_where, with_name=True):
    """Return CTE SQL for base SKUs: WITH base_sku AS (SELECT m.sku ... WHERE 1=1 {base_where}). Optionally include 'WITH base_sku AS'."""
    sql = f"(SELECT m.sku FROM sku_master m WHERE 1=1 {base_where})"
    return f"WITH base_sku AS {sql}" if with_name else sql


# ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼ (ìºì‹œ: cat/wh/sku_pick/horizon/model/lookback/latest_date ë³€ê²½ ì‹œ ì¬ê³„ì‚°)
forecast_daily = compute_forecast(demand, sku, inv, cat, wh, sku_pick, str(latest_date), horizon_days, model_type, lookback_days)
latest_inv_df = con.execute(f"""
  SELECT sku, warehouse, onhand_qty
  FROM inventory_daily
  WHERE date = '{latest_date}'
  {_inv_wh_where(wh)}
""").fetchdf()
forecast_metrics_df = pd.DataFrame()
if not forecast_daily.empty and not latest_inv_df.empty:
    forecast_metrics_df = compute_forecast_metrics(forecast_daily, latest_inv_df, horizon_days, latest_date)

# --- Ops Header ---
st.markdown("---")
st.markdown(f"**ê¸°ì¤€ì¼** `{fmt_date(latest_date)}`")
filter_parts = []
if cat != "ALL":
    filter_parts.append(f"ì¹´í…Œê³ ë¦¬: {category_map.get(cat, cat)}")
if wh != "ALL":
    filter_parts.append(f"ì°½ê³ : {warehouse_map.get(wh, wh)}")
if sku_pick != "ALL":
    filter_parts.append(f"SKU: {sku_pick}")
st.caption(" Â· ".join(filter_parts) if filter_parts else "í•„í„° ì—†ìŒ (ì „ì²´ ì¹´í…Œê³ ë¦¬Â·ì°½ê³ Â·SKU)")
st.caption(f"ì˜ˆì¸¡: {model_type} Â· í•™ìŠµ {lookback_days}ì¼ Â· ì˜ˆì¸¡ ê¸°ê°„ {horizon_days}ì¼")
st.markdown("---")

# Lightweight counts for "Recommended next step" (fixed dos_basis=14)
_summary_sql = f"""
WITH base_sku AS (SELECT m.sku FROM sku_master m WHERE 1=1 {base_where}),
latest_inv AS (SELECT sku, SUM(onhand_qty) AS onhand_qty FROM inventory_daily WHERE date = '{latest_date}' {_inv_wh_where(wh)} GROUP BY sku),
demand_14 AS (SELECT sku, SUM(demand_qty) AS demand_14 FROM demand_daily WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY AND date <= '{latest_date}' GROUP BY sku),
sku_dos AS (
  SELECT b.sku,
    CASE WHEN COALESCE(d.demand_14, 0) > 0 THEN ROUND(COALESCE(li.onhand_qty, 0) * 14.0 / NULLIF(d.demand_14, 0), 1) ELSE NULL END AS coverage_days
  FROM base_sku b
  LEFT JOIN latest_inv li ON b.sku = li.sku
  LEFT JOIN demand_14 d ON b.sku = d.sku
)
SELECT
  (SELECT COUNT(*) FROM sku_dos WHERE coverage_days IS NOT NULL AND coverage_days < 14) AS stockout_cnt,
  (SELECT COUNT(*) FROM sku_dos WHERE coverage_days IS NOT NULL AND coverage_days > 60) AS overstock_cnt
"""
try:
    _summary = con.execute(_summary_sql).fetchdf().iloc[0]
    summary_stockout_cnt = int(pd.to_numeric(_summary["stockout_cnt"], errors="coerce")) if pd.notna(_summary["stockout_cnt"]) else 0
    summary_overstock_cnt = int(pd.to_numeric(_summary["overstock_cnt"], errors="coerce")) if pd.notna(_summary["overstock_cnt"]) else 0
except Exception:
    summary_stockout_cnt = 0
    summary_overstock_cnt = 0

# --- Tabs ---
tab_exec, tab_health, tab_stockout, tab_actions, tab_movements = st.tabs([
    "Overview",
    "ì¬ê³  ì ì •ì„±",
    "í’ˆì ˆ ìœ„í—˜",
    "ë°œì£¼Â·ì¡°ì¹˜",
    "ì…ì¶œê³  ì¶”ì ",
])

with tab_exec:
    st.subheader("Overview")
    st.caption("ê¸°ì¤€ì¼ KPIÂ·ìš°ì„  ì ê²€ ì´ìŠˆÂ·ì¶”ì´Â·ì¹´í…Œê³ ë¦¬ ë¹„ì¤‘ì„ í•œëˆˆì— ë³´ê³ , ë°”ë¡œ í•  ì¼ë¶€í„° ì§„í–‰í•˜ì„¸ìš”.")
    if summary_stockout_cnt > 0:
        st.info("**ë°”ë¡œ í•  ì¼:** **í’ˆì ˆ ìœ„í—˜** íƒ­ì—ì„œ Critical SKUë¶€í„° í™•ì¸í•˜ì„¸ìš”.")
    elif summary_overstock_cnt > 0:
        st.info("**ë°”ë¡œ í•  ì¼:** **ì¬ê³  ì ì •ì„±** íƒ­ì—ì„œ ê³¼ì‰ êµ¬ê°„ì„ í™•ì¸í•œ ë’¤ **ë°œì£¼Â·ì¡°ì¹˜** íƒ­ì—ì„œ ì¡°ì¹˜í•˜ì„¸ìš”.")
    else:
        st.info("**ë°”ë¡œ í•  ì¼:** **ì¬ê³  ì ì •ì„±**Â·**í’ˆì ˆ ìœ„í—˜** íƒ­ì—ì„œ ì˜ˆì™¸ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    st.markdown(f"**ì ìš© ì˜ˆì¸¡:** {model_type} Â· í•™ìŠµ {lookback_days}ì¼ Â· ì˜ˆì¸¡ ê¸°ê°„ {horizon_days}ì¼")

    st.markdown("#### 1. í˜„í™© ìš”ì•½ (ê¸°ì¤€ì¼ ê¸°ì¤€)")
    ov_trend_opts = [30, 60, 90, 180, "ALL"]
    ov_dos_opts = [7, 14, 30]
    col_ov1, col_ov2 = st.columns(2)
    with col_ov1:
        trend_days_val = st.selectbox(
            "ì¶”ì´ ì¡°íšŒ ê¸°ê°„(ì¼)",
            options=ov_trend_opts,
            index=ov_trend_opts.index(st.session_state.get("ov_trend_days", 60)) if st.session_state.get("ov_trend_days", 60) in ov_trend_opts else 1,
            format_func=lambda x: "ì „ì²´(365ì¼)" if x == "ALL" else f"{x}ì¼",
            key="ov_trend_days",
        )
    with col_ov2:
        dos_basis_days = st.selectbox(
            "DOS ì‚°ì • ê¸°ì¤€(ìµœê·¼ Nì¼ í‰ê·  ì¼ìˆ˜ìš”)",
            options=ov_dos_opts,
            index=ov_dos_opts.index(st.session_state.get("ov_dos_basis_days", 14)) if st.session_state.get("ov_dos_basis_days", 14) in ov_dos_opts else 1,
            format_func=lambda x: f"{x}ì¼",
            key="ov_dos_basis_days",
        )
    trend_days = 365 if trend_days_val == "ALL" else trend_days_val

    # KPI: dos_basis_days ê¸°ì¤€ median_dos, stockout(<14ì¼), overstock(>60ì¼)
    exec_kpi_sql = f"""
    WITH base_sku AS (SELECT m.sku, m.sku_name, m.category FROM sku_master m WHERE 1=1 {base_where}),
    latest_inv AS (
      SELECT sku, SUM(onhand_qty) AS onhand_qty
      FROM inventory_daily
      WHERE date = '{latest_date}'
      {_inv_wh_where(wh)}
      GROUP BY sku
    ),
    demand_Nd AS (
      SELECT sku, SUM(demand_qty) AS demand_Nd
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL {dos_basis_days} DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    sku_dos AS (
      SELECT
        b.sku,
        COALESCE(li.onhand_qty, 0) AS onhand_qty,
        COALESCE(d.demand_Nd, 0) AS demand_Nd,
        CASE WHEN COALESCE(d.demand_Nd, 0) > 0
          THEN ROUND(COALESCE(li.onhand_qty, 0) * {dos_basis_days} * 1.0 / NULLIF(d.demand_Nd, 0), 1)
          ELSE NULL END AS coverage_days
      FROM base_sku b
      LEFT JOIN latest_inv li ON b.sku = li.sku
      LEFT JOIN demand_Nd d ON b.sku = d.sku
    )
    SELECT
      (SELECT COALESCE(SUM(onhand_qty), 0) FROM sku_dos) AS total_onhand,
      (SELECT COALESCE(SUM(demand_Nd), 0) FROM sku_dos) AS total_demand_Nd,
      (SELECT MEDIAN(coverage_days) FROM sku_dos WHERE coverage_days IS NOT NULL) AS median_dos,
      (SELECT COUNT(*) FROM sku_dos WHERE coverage_days IS NOT NULL AND coverage_days < 14) AS stockout_sku_cnt,
      (SELECT COUNT(*) FROM sku_dos WHERE coverage_days IS NOT NULL AND coverage_days > 60) AS overstock_sku_cnt
    """
    exec_kpi = con.execute(exec_kpi_sql).fetchdf().iloc[0]
    # Deltas vs 7 days ago (onhand) and vs previous 7 days (demand)
    delta_sql = f"""
    WITH base_sku AS (SELECT m.sku FROM sku_master m WHERE 1=1 {base_where}),
    inv_now AS (SELECT SUM(onhand_qty) AS v FROM inventory_daily i JOIN base_sku b ON i.sku = b.sku WHERE i.date = '{latest_date}' {_inv_wh_where(wh)}),
    inv_7d AS (SELECT SUM(onhand_qty) AS v FROM inventory_daily i JOIN base_sku b ON i.sku = b.sku WHERE i.date = '{latest_date}'::DATE - INTERVAL 7 DAY {_inv_wh_where(wh)}),
    demand_cur_7 AS (SELECT COALESCE(SUM(d.demand_qty), 0) AS v FROM demand_daily d JOIN base_sku b ON d.sku = b.sku WHERE d.date > '{latest_date}'::DATE - INTERVAL 7 DAY AND d.date <= '{latest_date}'::DATE),
    demand_prev_7 AS (SELECT COALESCE(SUM(d.demand_qty), 0) AS v FROM demand_daily d JOIN base_sku b ON d.sku = b.sku WHERE d.date > '{latest_date}'::DATE - INTERVAL 14 DAY AND d.date <= '{latest_date}'::DATE - INTERVAL 7 DAY)
    SELECT (SELECT COALESCE(v, 0) FROM inv_now) AS onhand_now, (SELECT COALESCE(v, 0) FROM inv_7d) AS onhand_7d_ago,
           (SELECT COALESCE(v, 0) FROM demand_cur_7) AS demand_cur_7, (SELECT COALESCE(v, 0) FROM demand_prev_7) AS demand_prev_7
    """
    try:
        delta_row = con.execute(delta_sql).fetchdf().iloc[0]
        onhand_now = int(pd.to_numeric(delta_row["onhand_now"], errors="coerce")) if pd.notna(delta_row["onhand_now"]) else 0
        onhand_7d = int(pd.to_numeric(delta_row["onhand_7d_ago"], errors="coerce")) if pd.notna(delta_row["onhand_7d_ago"]) else 0
        demand_cur_7 = int(pd.to_numeric(delta_row["demand_cur_7"], errors="coerce")) if pd.notna(delta_row["demand_cur_7"]) else 0
        demand_prev_7 = int(pd.to_numeric(delta_row["demand_prev_7"], errors="coerce")) if pd.notna(delta_row["demand_prev_7"]) else 0
        delta_onhand = (onhand_now - onhand_7d) if (onhand_now or onhand_7d) else None
        delta_demand = (demand_cur_7 - demand_prev_7) if (demand_cur_7 is not None and demand_prev_7 is not None) else None
    except Exception:
        delta_onhand = None
        delta_demand = None

    col1, col2, col3, col4, col5 = st.columns(5)
    total_onhand = int(pd.to_numeric(exec_kpi["total_onhand"], errors="coerce")) if pd.notna(exec_kpi["total_onhand"]) else 0
    total_demand_Nd = int(pd.to_numeric(exec_kpi["total_demand_Nd"], errors="coerce")) if pd.notna(exec_kpi["total_demand_Nd"]) else 0
    median_dos_val = exec_kpi["median_dos"]
    median_dos_str = f"{median_dos_val:,.1f}" if pd.notna(median_dos_val) and (median_dos_val == median_dos_val) else "â€”"
    stockout_sku_cnt = int(pd.to_numeric(exec_kpi["stockout_sku_cnt"], errors="coerce")) if pd.notna(exec_kpi["stockout_sku_cnt"]) else 0
    overstock_sku_cnt = int(pd.to_numeric(exec_kpi["overstock_sku_cnt"], errors="coerce")) if pd.notna(exec_kpi["overstock_sku_cnt"]) else 0
    col1.metric("í˜„ì¬ ì¬ê³ (ì´ ìˆ˜ëŸ‰)", fmt_qty(total_onhand), delta=delta_onhand if delta_onhand is not None else None)
    col2.metric(f"ìµœê·¼ {dos_basis_days}ì¼ ìˆ˜ìš” í•©ê³„", fmt_qty(total_demand_Nd), delta=delta_demand if delta_demand is not None else None)
    col3.metric("ì»¤ë²„ë¦¬ì§€(DOS) ì¤‘ì•™ê°’(ì¼)", median_dos_str)
    col4.metric("í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜ (DOS 14ì¼ ë¯¸ë§Œ)", fmt_qty(stockout_sku_cnt))
    col5.metric("ê³¼ì‰ ì¬ê³  SKU ìˆ˜ (DOS 60ì¼ ì´ˆê³¼)", fmt_qty(overstock_sku_cnt))

    st.caption(f"DOS(ì¬ê³  ì»¤ë²„ë¦¬ì§€ ì¼ìˆ˜) = ì¬ê³  Ã· ì¼í‰ê·  ìˆ˜ìš”. ê¸°ì¤€: ìµœê·¼ {dos_basis_days}ì¼. í’ˆì ˆ ìœ„í—˜ 14ì¼ ë¯¸ë§Œ, ê³¼ì‰ 60ì¼ ì´ˆê³¼.")

    st.markdown("#### ìš°ì„  ì ê²€ ì´ìŠˆ (ìƒìœ„ 5ê±´)")
    hot_sql = f"""
    WITH base_sku AS (SELECT m.sku, m.sku_name FROM sku_master m WHERE 1=1 {base_where}),
    latest_inv AS (
      SELECT sku, warehouse, onhand_qty
      FROM inventory_daily
      WHERE date = '{latest_date}' {_inv_wh_where(wh)}
    ),
    demand_14 AS (SELECT sku, SUM(demand_qty) AS demand_14d FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY AND date <= '{latest_date}' GROUP BY sku),
    demand_30 AS (SELECT sku, SUM(demand_qty) AS demand_30d FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 30 DAY AND date <= '{latest_date}' GROUP BY sku)
    SELECT b.sku, b.sku_name, li.warehouse,
      COALESCE(li.onhand_qty, 0) AS onhand_qty,
      COALESCE(d14.demand_14d, 0) AS demand_14d,
      COALESCE(d30.demand_30d, 0) AS demand_30d,
      CASE WHEN COALESCE(d14.demand_14d, 0) > 0
        THEN ROUND(COALESCE(li.onhand_qty, 0) * 14.0 / NULLIF(d14.demand_14d, 0), 1) ELSE NULL END AS coverage_days
    FROM base_sku b
    LEFT JOIN latest_inv li ON b.sku = li.sku
    LEFT JOIN demand_14 d14 ON b.sku = d14.sku
    LEFT JOIN demand_30 d30 ON b.sku = d30.sku
    """
    hot_df = con.execute(hot_sql).fetchdf()
    if not hot_df.empty and not forecast_metrics_df.empty and "stockout_date_forecast" in forecast_metrics_df.columns:
        hot_df = hot_df.merge(
            forecast_metrics_df[["sku", "stockout_date_forecast"]].drop_duplicates("sku"),
            on="sku", how="left"
        )
    else:
        hot_df["stockout_date_forecast"] = pd.NaT
    lead_days_hot = st.session_state.get("lead_time_days", 7)
    shortage_days_hot = 14
    over_days_hot = 60
    issues = []
    for _, row in hot_df.iterrows():
        cov = row.get("coverage_days")
        onhand = int(row.get("onhand_qty", 0) or 0)
        d14 = float(row.get("demand_14d", 0) or 0)
        d30 = float(row.get("demand_30d", 0) or 0)
        stockout_d = row.get("stockout_date_forecast")
        issue_type = None
        severity = "Medium"
        rec_qty = None
        if cov is not None and cov < shortage_days_hot and (d14 > 0 or d30 > 0):
            issue_type = "í’ˆì ˆ ì„ë°•"
            severity = "Critical" if (cov is not None and cov < 7) else ("High" if (cov is not None and cov < 14) else "Medium")
            if d14 > 0:
                target = max(0, int(math.ceil(d14 / 14 * (lead_days_hot + shortage_days_hot))))
                rec_qty = max(0, target - onhand)
        elif d30 > 0 and cov is not None and cov < 21:
            p75_d30 = hot_df["demand_30d"].quantile(0.75) if len(hot_df) else 0
            if d30 >= p75_d30:
                issue_type = "ê³ ìˆ˜ìš”Â·ì €ì»¤ë²„ë¦¬ì§€"
                severity = "High" if (cov is not None and cov < 14) else "Medium"
                if d14 > 0:
                    target = max(0, int(math.ceil(d14 / 14 * (lead_days_hot + shortage_days_hot))))
                    rec_qty = max(0, target - onhand)
        if issue_type is None and cov is not None and cov > over_days_hot:
            p25_d30 = hot_df["demand_30d"].quantile(0.25) if len(hot_df) else 0
            if d30 <= p25_d30 and d30 == d30:
                issue_type = "ê³¼ì‰Â·ì €íšŒì „"
                severity = "Medium"
        if issue_type is None and d30 == 0 and onhand > 0:
            issue_type = "ë¬´ìˆ˜ìš” ì¬ê³ "
            severity = "Medium"
        if issue_type is not None:
            issues.append({
                "SKU": row["sku"],
                "ì°½ê³ ": row.get("warehouse") or "â€”",
                "ì´ìŠˆ ìœ í˜•": issue_type,
                "ì‹¬ê°ë„": severity,
                "ì˜ˆìƒ í’ˆì ˆì¼": fmt_date(stockout_d) if pd.notna(stockout_d) else "â€”",
                "ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰": rec_qty if rec_qty is not None else "â€”",
            })
    hot_issues_df = pd.DataFrame(issues)
    if not hot_issues_df.empty:
        sev_order = {"Critical": 0, "High": 1, "Medium": 2}
        hot_issues_df["_sev"] = hot_issues_df["ì‹¬ê°ë„"].map(sev_order)
        hot_issues_df = hot_issues_df.sort_values(["_sev", "ì´ìŠˆ ìœ í˜•"]).drop(columns=["_sev"]).head(5)
        st.dataframe(hot_issues_df, use_container_width=True, hide_index=True)
    else:
        st.caption("í˜„ì¬ í•„í„°ì—ì„œ ìš°ì„  ì ê²€ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    st.markdown("#### 2. ë¯¸ë˜ ì „ë§ (ì˜ˆì¸¡ ê¸°ì¤€)")
    if not forecast_daily.empty:
        mape_pct, mape_n = compute_mape_backtest(demand, lookback_days, model_type, str(latest_date), 14)
        if mape_pct is not None:
            if mape_pct < 20:
                confidence_hint = "ë†’ìŒ"
            elif mape_pct < 40:
                confidence_hint = "ë³´í†µ"
            else:
                confidence_hint = "ë‚®ìŒ"
        else:
            confidence_hint = "â€”"
        with st.expander("ëª¨ë¸ ì„¤ëª…"):
            st.write("**MovingAvg(N):** ìµœê·¼ Nì¼ ìˆ˜ìš” í‰ê· ìœ¼ë¡œ ì¼ë³„ ì˜ˆì¸¡. ë‹¨ìˆœÂ·ì•ˆì •ì .")
            st.write("**SeasonalNaive(N):** ìµœê·¼ Nì¼ íŒ¨í„´ì„ ì¼ë³„ë¡œ ë°˜ë³µ. ì£¼ê°„ ê³„ì ˆì„±ì— ì í•©.")
            st.write(f"**í•™ìŠµ êµ¬ê°„:** ìµœê·¼ {lookback_days}ì¼. **ë§ˆì§€ë§‰ ì‚¬ìš©ì¼:** {fmt_date(latest_date)}.")
        forecast_total = int(forecast_daily["forecast_qty"].sum())
        latest_dt = pd.to_datetime(latest_date)
        f7_cut = latest_dt + pd.Timedelta(days=7)
        lead_days = st.session_state.get("lead_time_days", 7)
        lead_cut = latest_dt + pd.Timedelta(days=lead_days)
        f_daily = forecast_daily.copy()
        f_daily["date"] = pd.to_datetime(f_daily["date"])
        forecast_next7 = int(f_daily[f_daily["date"] <= f7_cut]["forecast_qty"].sum())
        lead_time_total = int(f_daily[f_daily["date"] <= lead_cut]["forecast_qty"].sum())
        horizon_cut = latest_dt + pd.Timedelta(days=horizon_days)
        risk_in_horizon = 0
        if not forecast_metrics_df.empty and "stockout_date_forecast" in forecast_metrics_df.columns:
            fm = forecast_metrics_df[forecast_metrics_df["stockout_date_forecast"].notna()].copy()
            fm["stockout_date_forecast"] = pd.to_datetime(fm["stockout_date_forecast"])
            risk_in_horizon = int((fm["stockout_date_forecast"] <= horizon_cut).sum())
        col_f1, col_f2, col_f3 = st.columns(3)
        col_f1.metric(f"í–¥í›„ {horizon_days}ì¼ ì˜ˆìƒ ìˆ˜ìš” í•©ê³„", fmt_qty(forecast_total))
        col_f2.metric(
            f"í–¥í›„ {lead_days}ì¼ ì˜ˆìƒ ìˆ˜ìš”" + (" (ë¦¬ë“œíƒ€ì„ êµ¬ê°„)" if lead_days != 7 else ""),
            fmt_qty(lead_time_total if lead_days != 7 else forecast_next7),
        )
        col_f3.metric(f"ì˜ˆì¸¡ ê¸°ì¤€ í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜ (í–¥í›„ {horizon_days}ì¼ ì´ë‚´)", fmt_qty(risk_in_horizon))
        if mape_pct is not None:
            st.caption(f"**MAPE(í‰ê· ì ˆëŒ€ë°±ë¶„ìœ¨ì˜¤ì°¨)** ìµœê·¼ 14ì¼ ë°±í…ŒìŠ¤íŠ¸: {mape_pct:.1f}% (n={mape_n}). ì°¸ê³ ìš©ì´ë©°, **ì˜ˆì¸¡ ì‹ ë¢°ë„:** {confidence_hint} (20% ë¯¸ë§Œ=ë†’ìŒ, 20â€“40%=ë³´í†µ, 40% ì´ˆê³¼=ë‚®ìŒ).")
    else:
        st.caption("ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì˜ˆì¸¡ ì„¤ì •Â·ì¡°íšŒ ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”.")

    st.divider()
    st.markdown("#### 3. ìˆ˜ìš”Â·ì¬ê³  ì¶”ì´")
    show_forecast_overlay = st.toggle("ì˜ˆì¸¡ì„  í‘œì‹œ", value=True, key="ov_show_forecast_overlay")
    trend_sql = f"""
    {_base_sku_cte(base_where)}
    SELECT d.date, SUM(d.demand_qty) AS demand_qty
    FROM demand_daily d
    JOIN base_sku b ON d.sku = b.sku
    WHERE d.date >= '{latest_date}'::DATE - INTERVAL {trend_days} DAY
    GROUP BY d.date
    ORDER BY d.date
    """
    trend = con.execute(trend_sql).fetchdf()
    inv_trend_sql = f"""
    {_base_sku_cte(base_where)}
    SELECT i.date, SUM(i.onhand_qty) AS onhand_qty
    FROM inventory_daily i
    JOIN base_sku b ON i.sku = b.sku
    WHERE i.date >= '{latest_date}'::DATE - INTERVAL {trend_days} DAY
    {_inv_wh_where(wh)}
    GROUP BY i.date
    ORDER BY i.date
    """
    inv_trend = con.execute(inv_trend_sql).fetchdf()

    col_trend_demand, col_trend_inv = st.columns(2)
    with col_trend_demand:
        fig_trend = px.line(trend, x="date", y="demand_qty", title=f"ìˆ˜ìš” ì¶”ì´ (ìµœê·¼ {trend_days}ì¼)" if trend_days != 365 else "ìˆ˜ìš” ì¶”ì´ (ì „ì²´)")
        fig_trend.update_traces(name="ì‹¤ì  ìˆ˜ìš”")
        if show_forecast_overlay and not forecast_daily.empty:
            forecast_agg = forecast_daily.groupby("date")["forecast_qty"].sum().reset_index()
            fig_trend.add_scatter(
                x=forecast_agg["date"],
                y=forecast_agg["forecast_qty"],
                name="ì˜ˆì¸¡ ìˆ˜ìš”",
                line=dict(dash="dash", color="orange"),
                mode="lines",
            )
            latest_dt_trend = pd.to_datetime(latest_date)
            horizon_end = latest_dt_trend + pd.Timedelta(days=horizon_days)
            add_ref_vrect(fig_trend, latest_dt_trend, horizon_end, label="Forecast horizon", fill_color="rgba(255,165,0,0.15)", line_color="orange")
        add_ref_vline(fig_trend, latest_date, "ê¸°ì¤€ì¼", line_dash="dot", line_color="gray")
        fig_trend.update_layout(xaxis_title="ì¼ì", yaxis_title="ìˆ˜ìš”ëŸ‰", legend_title=None)
        fig_trend.update_xaxes(tickformat="%Y-%m-%d")
        fig_trend.update_yaxes(tickformat=",.0f")
        fig_trend = apply_plotly_theme(fig_trend)
        st.plotly_chart(fig_trend, use_container_width=True)
    with col_trend_inv:
        fig_inv_trend = px.line(inv_trend, x="date", y="onhand_qty", title=f"ì¬ê³  ì¶”ì´ (ìµœê·¼ {trend_days}ì¼)" if trend_days != 365 else "ì¬ê³  ì¶”ì´ (ì „ì²´)")
        fig_inv_trend.update_layout(xaxis_title="ì¼ì", yaxis_title="ì¬ê³  ìˆ˜ëŸ‰")
        fig_inv_trend.update_xaxes(tickformat="%Y-%m-%d")
        fig_inv_trend.update_yaxes(tickformat=",.0f")
        fig_inv_trend = apply_plotly_theme(fig_inv_trend)
        st.plotly_chart(fig_inv_trend, use_container_width=True)

    st.divider()
    st.markdown("#### 4. ì¹´í…Œê³ ë¦¬ë³„ ë¹„ì¤‘")
    cat_inv_sql = f"""
    SELECT m.category, COALESCE(SUM(i.onhand_qty), 0) AS onhand_qty
    FROM sku_master m
    LEFT JOIN inventory_daily i ON i.sku = m.sku AND i.date = '{latest_date}' {_inv_wh_join(wh)}
    WHERE 1=1
    {base_where}
    GROUP BY m.category
    ORDER BY onhand_qty DESC
    """
    cat_inv = con.execute(cat_inv_sql).fetchdf()

    if not cat_inv.empty and cat_inv["onhand_qty"].sum() > 0:
        total_inv = cat_inv["onhand_qty"].sum()
        cat_inv = cat_inv.assign(pct=(cat_inv["onhand_qty"] / total_inv * 100))
        top5_inv = cat_inv.head(5)
        others_inv = cat_inv.iloc[5:]
        if len(others_inv) > 0:
            others_row = pd.DataFrame([{"category": "Others", "onhand_qty": others_inv["onhand_qty"].sum(), "pct": others_inv["pct"].sum()}])
            cat_inv_display = pd.concat([top5_inv, others_row], ignore_index=True)
        else:
            cat_inv_display = top5_inv.copy()
        cat_inv_display["category_ko"] = cat_inv_display["category"].map(lambda x: category_map.get(x, x))
        cat_inv_display["label"] = cat_inv_display.apply(lambda r: f"{r['category_ko']} ({fmt_pct(r['pct'])})", axis=1)
        fig_cat_inv = px.bar(
            cat_inv_display,
            x="onhand_qty",
            y="label",
            orientation="h",
            title="ì¹´í…Œê³ ë¦¬ë³„ ì¬ê³  ë¹„ì¤‘ (ê¸°ì¤€ì¼) â€” ìˆ˜ëŸ‰Â·%",
            labels={"onhand_qty": "ì¬ê³  ìˆ˜ëŸ‰", "label": "ì¹´í…Œê³ ë¦¬"},
        )
        fig_cat_inv.update_layout(
            yaxis={"categoryorder": "total ascending"},
            bargap=0.6,
        )
        fig_cat_inv.update_xaxes(tickformat=",.0f")
        fig_cat_inv.update_traces(
            marker_color=["#b5dde8", "#8fc9dc", "#6bb5d0", "#52a0c4", "#4a90b0", "#3d7d98"],
            marker_line_color="rgba(255,255,255,0.9)",
            marker_line_width=0.5,
        )
        fig_cat_inv = apply_plotly_theme(fig_cat_inv)
        st.plotly_chart(fig_cat_inv, use_container_width=True)
    else:
        st.caption("ì¹´í…Œê³ ë¦¬ë³„ ì¬ê³  ë¹„ì¤‘: ë°ì´í„° ì—†ìŒ")

    # ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ìš” ë¹„ì¤‘: cat=ALL, sku_pick=ALL ì¼ ë•Œë§Œ í‘œì‹œ
    if cat == "ALL" and sku_pick == "ALL":
        cat_demand_sql = f"""
        SELECT m.category, COALESCE(SUM(d.demand_qty), 0) AS demand_qty
        FROM sku_master m
        LEFT JOIN demand_daily d ON d.sku = m.sku
          AND d.date > '{latest_date}'::DATE - INTERVAL 30 DAY AND d.date <= '{latest_date}'
        WHERE 1=1
        {base_where}
        GROUP BY m.category
        ORDER BY demand_qty DESC
        """
        cat_demand = con.execute(cat_demand_sql).fetchdf()
        if not cat_demand.empty and cat_demand["demand_qty"].sum() > 0:
            total_demand = cat_demand["demand_qty"].sum()
            cat_demand = cat_demand.assign(pct=(cat_demand["demand_qty"] / total_demand * 100))
            top5_demand = cat_demand.head(5)
            others_demand = cat_demand.iloc[5:]
            if len(others_demand) > 0:
                others_row_d = pd.DataFrame([{"category": "Others", "demand_qty": others_demand["demand_qty"].sum(), "pct": others_demand["pct"].sum()}])
                cat_demand_display = pd.concat([top5_demand, others_row_d], ignore_index=True)
            else:
                cat_demand_display = top5_demand.copy()
            cat_demand_display["category_ko"] = cat_demand_display["category"].map(lambda x: category_map.get(x, x))
            cat_demand_display["label"] = cat_demand_display.apply(lambda r: f"{r['category_ko']} ({fmt_pct(r['pct'])})", axis=1)
            fig_cat_demand = px.bar(
                cat_demand_display,
                x="demand_qty",
                y="label",
                orientation="h",
                title="ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ìš” ë¹„ì¤‘ (ìµœê·¼ 30ì¼) â€” ìˆ˜ëŸ‰Â·%",
                labels={"demand_qty": "ìˆ˜ìš”ëŸ‰", "label": "ì¹´í…Œê³ ë¦¬"},
            )
            fig_cat_demand.update_layout(yaxis={"categoryorder": "total ascending"}, bargap=0.6)
            fig_cat_demand.update_xaxes(tickformat=",.0f")
            fig_cat_demand = apply_plotly_theme(fig_cat_demand)
            st.plotly_chart(fig_cat_demand, use_container_width=True)
    else:
        st.caption("ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ìš” ë¹„ì¤‘: ì „ì²´ ì¹´í…Œê³ ë¦¬Â·ì „ì²´ SKU ì„ íƒ ì‹œì—ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

    st.divider()
    st.markdown("#### 5. ìš°ì„  ì¡°ì¹˜ ìƒìœ„ 10ê±´")
    if not forecast_metrics_df.empty and not forecast_daily.empty:
        lead_time_days_ov = st.session_state.get("lead_time_days", 7)
        target_cover_days_ov = st.session_state.get("target_cover_days", 14)
        safety_stock_days_ov = st.session_state.get("safety_stock_days", 3)
        moq_ov = st.session_state.get("moq", 0)
        actions_sql_ov = f"""
        WITH base_sku AS (
          SELECT m.sku, m.sku_name, m.category
          FROM sku_master m
          WHERE 1=1
          {base_where}
        ),
        latest_inv AS (
          SELECT sku, warehouse, onhand_qty
          FROM inventory_daily
          WHERE date = '{latest_date}'
          {_inv_wh_where(wh)}
        ),
        base AS (
          SELECT b.sku, b.sku_name, b.category, li.warehouse, COALESCE(li.onhand_qty, 0) AS onhand_qty
          FROM base_sku b
          LEFT JOIN latest_inv li ON b.sku = li.sku
        )
        SELECT sku, sku_name, category, warehouse, onhand_qty FROM base
        """
        actions_base_ov = con.execute(actions_sql_ov).fetchdf()
        latest_dt_ov = pd.to_datetime(latest_date)
        lead_cut_ov = latest_dt_ov + pd.Timedelta(days=lead_time_days_ov)
        f_daily_ov = forecast_daily.copy()
        f_daily_ov["date"] = pd.to_datetime(f_daily_ov["date"])
        f_lead_ov = f_daily_ov[f_daily_ov["date"] <= lead_cut_ov].groupby("sku")["forecast_qty"].sum()
        f_metrics_ov = forecast_metrics_df[["sku", "forecast_avg_daily", "forecast_dos", "stockout_date_forecast"]].drop_duplicates("sku")
        actions_base_ov = actions_base_ov.merge(f_metrics_ov, on="sku", how="inner")
        actions_base_ov["lead_time_forecast"] = actions_base_ov["sku"].map(lambda s: f_lead_ov.get(s, 0) if s in f_lead_ov.index else 0)
        fa_ov = actions_base_ov["forecast_avg_daily"].fillna(0)
        lt_f_ov = actions_base_ov["lead_time_forecast"].fillna(0)
        target_stock_ov = (lt_f_ov + fa_ov * target_cover_days_ov + fa_ov * safety_stock_days_ov).round(0).astype(int)
        onhand_ov = pd.to_numeric(actions_base_ov["onhand_qty"], errors="coerce").fillna(0)
        rec_ov = (target_stock_ov - onhand_ov).clip(lower=0).astype(int)
        if moq_ov > 0:
            rec_ov = rec_ov.where(rec_ov <= 0, rec_ov.clip(lower=moq_ov)).astype(int)
        actions_base_ov["target_stock"] = target_stock_ov
        actions_base_ov["recommended_order_qty"] = rec_ov
        actions_base_ov["estimated_stockout_date"] = actions_base_ov["stockout_date_forecast"]
        actions_base_ov["coverage_days"] = actions_base_ov["forecast_dos"]
        def reason_ov(row):
            if pd.notna(row["coverage_days"]) and row["coverage_days"] < target_cover_days_ov:
                return "ì˜ˆì¸¡ í’ˆì ˆ ì„ë°•"
            if row["onhand_qty"] < row["target_stock"]:
                return "ë¦¬ë“œíƒ€ì„ ìˆ˜ìš” ëŒ€ë¹„ ë¶€ì¡±"
            return "ì •ì±… ë³´ì¶©"
        actions_base_ov["reason"] = actions_base_ov.apply(reason_ov, axis=1)
        top10 = actions_base_ov[actions_base_ov["recommended_order_qty"] > 0].copy()
        top10 = top10.sort_values(["estimated_stockout_date", "recommended_order_qty"], ascending=[True, False], na_position="last").head(10)
        display_top10 = top10[["sku", "sku_name", "warehouse", "estimated_stockout_date", "coverage_days", "recommended_order_qty", "reason"]].copy()
        display_top10 = display_top10.rename(columns={"estimated_stockout_date": "ì˜ˆìƒ í’ˆì ˆì¼(ì˜ˆì¸¡)", "coverage_days": "DOS(ì˜ˆì¸¡)"})
        if display_top10.empty:
            st.caption("ê¶Œì¥ ë°œì£¼ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(display_top10, use_container_width=True)
            st.caption("ì „ì²´ ëª©ë¡Â·ì •ì±… ë³€ê²½ì€ **ë°œì£¼Â·ì¡°ì¹˜** íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.caption("ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì˜ˆì¸¡ ì„¤ì • ì ìš© í›„ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")

with tab_health:
    st.subheader("ì¬ê³  ì ì •ì„±")
    st.caption("ë¶€ì¡±Â·ì ì •Â·ê³¼ì‰ êµ¬ê°„ë³„ SKU ìˆ˜ì™€ DOS ë¶„í¬. í’ˆì ˆ ìœ„í—˜Â·ë°œì£¼Â·ì¡°ì¹˜ íƒ­ìœ¼ë¡œ ì´ì–´ì„œ ì¡°ì¹˜í•˜ì„¸ìš”.")
    if summary_stockout_cnt > 0:
        st.info("**ë°”ë¡œ í•  ì¼:** ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± SKUê°€ ìˆìŠµë‹ˆë‹¤. **í’ˆì ˆ ìœ„í—˜**Â·**ë°œì£¼Â·ì¡°ì¹˜** íƒ­ì—ì„œ ë°œì£¼ ê²€í† í•˜ì„¸ìš”.")
    st.markdown("**ê¸°ì¤€ ì„¤ì •**")
    # íƒ­ ë‚´ë¶€ í•„í„° 3ê°œ: dos_basis_days, shortage_days, over_days
    col_dos_basis, col_risk, col_over = st.columns(3)
    with col_dos_basis:
        health_dos_basis_days = st.selectbox(
            "DOS ì‚°ì • ê¸°ì¤€(ìµœê·¼ Nì¼ í‰ê·  ì¼ìˆ˜ìš”)",
            options=[7, 14, 30],
            index=[7, 14, 30].index(st.session_state.get("health_dos_basis_days", 14)) if st.session_state.get("health_dos_basis_days", 14) in [7, 14, 30] else 1,
            format_func=lambda x: f"{x}ì¼",
            key="health_dos_basis_days",
        )
    with col_risk:
        shortage_days = st.selectbox(
            "ë¶€ì¡± ê¸°ì¤€ì„ (ì¼)",
            options=[7, 14, 21],
            index=[7, 14, 21].index(st.session_state.get("health_shortage_days", 14)) if st.session_state.get("health_shortage_days", 14) in [7, 14, 21] else 1,
            format_func=lambda x: f"{x}ì¼ ë¯¸ë§Œ",
            key="health_shortage_days",
        )
    with col_over:
        over_days = st.selectbox(
            "ê³¼ì‰ ê¸°ì¤€ì„ (ì¼)",
            options=[30, 60, 90, 120],
            index=[30, 60, 90, 120].index(st.session_state.get("health_over_days", 60)) if st.session_state.get("health_over_days", 60) in [30, 60, 90, 120] else 1,
            format_func=lambda x: f"{x}ì¼ ì´ˆê³¼",
            key="health_over_days",
        )

    # Health SQL (íƒ­ ë‚´ë¶€ ì‹¤í–‰)
    health_sql_tab = f"""
    WITH base_sku AS (
      SELECT m.sku, m.sku_name, m.category
      FROM sku_master m
      WHERE 1=1
      {base_where}
    ),
    latest_inv AS (
      SELECT sku, warehouse, onhand_qty
      FROM inventory_daily
      WHERE date = '{latest_date}'
      {_inv_wh_where(wh)}
    ),
    demand_30d_cte AS (
      SELECT sku, SUM(demand_qty) AS demand_30d
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 30 DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    avg_daily_demand AS (
      SELECT sku, AVG(demand_qty) AS avg_daily_demand_Nd
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL {health_dos_basis_days} DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    base AS (
      SELECT
        b.sku, b.sku_name, b.category,
        li.warehouse,
        COALESCE(li.onhand_qty, 0) AS onhand_qty,
        COALESCE(d30.demand_30d, 0) AS demand_30d,
        COALESCE(ad.avg_daily_demand_Nd, 0) AS avg_daily_demand_Nd,
        CASE
          WHEN COALESCE(ad.avg_daily_demand_Nd, 0) = 0 THEN NULL
          ELSE ROUND(COALESCE(li.onhand_qty, 0) / ad.avg_daily_demand_Nd, 1)
        END AS coverage_days
      FROM base_sku b
      LEFT JOIN latest_inv li ON b.sku = li.sku
      LEFT JOIN demand_30d_cte d30 ON b.sku = d30.sku
      LEFT JOIN avg_daily_demand ad ON b.sku = ad.sku
    )
    SELECT sku, sku_name, category, warehouse, onhand_qty, demand_30d, avg_daily_demand_Nd, coverage_days
    FROM base
    ORDER BY coverage_days ASC NULLS LAST
    """
    health = con.execute(health_sql_tab).fetchdf()

    def assign_bucket(row):
        cd = row["coverage_days"]
        if pd.isna(cd):
            return "ìˆ˜ìš”0"
        if cd < shortage_days:
            return "ë¶€ì¡±"
        if cd > over_days:
            return "ê³¼ì‰"
        return "ì ì •"

    health["bucket"] = health.apply(assign_bucket, axis=1)
    health_with_dos = health[health["coverage_days"].notna()].copy()

    # êµ¬ê°„ë³„ SKU ìˆ˜ ì¹´ë“œ 4ê°œ + DOS ë¶„í¬ íˆìŠ¤í† ê·¸ë¨(ê¸°ì¤€ì„  + ë¶€ì¡±/ê³¼ì‰ ë¹„ìœ¨ ë¬¸ì¥)
    cnt_short = int((health["bucket"] == "ë¶€ì¡±").sum())
    cnt_ok = int((health["bucket"] == "ì ì •").sum())
    cnt_over = int((health["bucket"] == "ê³¼ì‰").sum())
    cnt_nodemand = int((health["bucket"] == "ìˆ˜ìš”0").sum())
    total_sku = len(health)
    pct_short = (cnt_short / total_sku * 100) if total_sku else 0
    pct_over = (cnt_over / total_sku * 100) if total_sku else 0

    st.markdown("**êµ¬ê°„ë³„ SKU ìˆ˜**")
    row_c1, row_c2, row_hist = st.columns([1, 1, 2])
    with row_c1:
        st.metric("ë¶€ì¡±", f"{cnt_short:,}ê±´")
        st.metric("ì ì •", f"{cnt_ok:,}ê±´")
    with row_c2:
        st.metric("ê³¼ì‰", f"{cnt_over:,}ê±´")
        st.metric(f"ìˆ˜ìš” ì—†ìŒ(ìµœê·¼ {health_dos_basis_days}ì¼)", f"{cnt_nodemand:,}ê±´")
    with row_hist:
        if not health_with_dos.empty:
            fig_hist = px.histogram(
                health_with_dos,
                x="coverage_days",
                nbins=min(40, max(10, len(health_with_dos) // 3)),
                title="ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS) ë¶„í¬ (ê¸°ì¤€ì„ : ë¶€ì¡±/ê³¼ì‰)",
                labels={"coverage_days": "ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)"},
            )
            fig_hist.update_layout(xaxis_title="ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)", yaxis_title="SKU ìˆ˜")
            fig_hist.update_yaxes(tickformat=",.0f")
            add_ref_vline(fig_hist, shortage_days, f"ë¶€ì¡± ê¸°ì¤€ì„ ({shortage_days}ì¼)", line_dash="dash", line_color="crimson")
            add_ref_vline(fig_hist, over_days, f"ê³¼ì‰ ê¸°ì¤€ì„ ({over_days}ì¼)", line_dash="dash", line_color="steelblue")
            fig_hist = apply_plotly_theme(fig_hist)
            st.plotly_chart(fig_hist, use_container_width=True)
            st.caption(f"ë¶€ì¡± ë¹„ìœ¨ {pct_short:.1f}% (ê¸°ì¤€ì„  {shortage_days}ì¼ ë¯¸ë§Œ) Â· ê³¼ì‰ ë¹„ìœ¨ {pct_over:.1f}% (ê¸°ì¤€ì„  {over_days}ì¼ ì´ˆê³¼)")
        else:
            st.caption(f"DOS ë°ì´í„° ì—†ìŒ. ìµœê·¼ {health_dos_basis_days}ì¼ ìˆ˜ìš” 0ì´ê±°ë‚˜ í•„í„° ê²°ê³¼ ì—†ìŒ.")

    # ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤(ê³ ìˆ˜ìš”Ã—ë¶€ì¡±): X=demand_30d(80% ë¶„ìœ„), Y=DOS(shortage_days ê¸°ì¤€ì„ ), ìˆ˜ìš” ì—†ìŒ êµ¬ê°„ ì œì™¸
    if not health_with_dos.empty:
        health_demand_cut = 0.8
        x_cut = float(health_with_dos["demand_30d"].quantile(health_demand_cut))
        y_cut = shortage_days

        fig_scatter = px.scatter(
            health_with_dos,
            x="demand_30d",
            y="coverage_days",
            size="demand_30d",
            color="bucket",
            color_discrete_map={"ë¶€ì¡±": "#e74c3c", "ì ì •": "#2ecc71", "ê³¼ì‰": "#3498db"},
            hover_data={
                "sku": True,
                "sku_name": True,
                "category": True,
                "onhand_qty": ",.0f",
                "demand_30d": ",.0f",
                "coverage_days": ",.1f",
                "bucket": True,
            },
            title="ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤(ê³ ìˆ˜ìš”Ã—ë¶€ì¡±)",
        )
        fig_scatter.update_layout(
            xaxis_title="ìµœê·¼ 30ì¼ ìˆ˜ìš”(ê°œ)",
            yaxis_title="ì¬ê³  ì»¤ë²„ ì¼ìˆ˜(DOS)",
        )
        fig_scatter.update_yaxes(tickformat=",.0f")
        fig_scatter.update_xaxes(tickformat=",.0f")
        add_ref_hline(fig_scatter, y_cut, f"ë¶€ì¡± ê¸°ì¤€({shortage_days}ì¼)", line_dash="dash", line_color="gray")
        add_ref_vline(fig_scatter, x_cut, "80% ë¶„ìœ„", line_dash="dash", line_color="gray")
        fig_scatter = apply_plotly_theme(fig_scatter)
        st.plotly_chart(fig_scatter, use_container_width=True)
        st.caption(
            "**ìš°í•˜** ê³ ìˆ˜ìš”Â·ì €DOS â†’ ìµœìš°ì„  ë°œì£¼ | **ì¢Œí•˜** ì €ìˆ˜ìš”Â·ì €DOS â†’ ì£¼ë¬¸ì£¼ê¸° ê²€í†  | "
            "**ìš°ìƒ** ê³ ìˆ˜ìš”Â·ê³ DOS â†’ ì ì • | **ì¢Œìƒ** ì €ìˆ˜ìš”Â·ê³ DOS â†’ ê³¼ì‰Â·ì¬ê³  ì¡°ì •."
        )
    else:
        st.caption("DOSê°€ ìˆëŠ” SKUê°€ ì—†ì–´ ì‚°ì ë„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    st.divider()
    st.markdown("**êµ¬ê°„ë³„ ìƒì„¸ ëª©ë¡**")
    bucket_order = {"ë¶€ì¡±": 0, "ê³¼ì‰": 1, "ì ì •": 2, "ìˆ˜ìš”0": 3}
    health["_bucket_order"] = health["bucket"].map(bucket_order)
    _nodemand_label = f"ìµœê·¼ {health_dos_basis_days}ì¼ ìˆ˜ìš” ì—†ìŒ(0)"
    bucket_options = ["ë¶€ì¡±", "ê³¼ì‰", "ì ì •", "ìˆ˜ìš”0"]
    default_buckets = ["ë¶€ì¡±", "ê³¼ì‰"] if show_only_exceptions else bucket_options
    selected_buckets = st.multiselect(
        "êµ¬ê°„",
        options=bucket_options,
        default=default_buckets,
        format_func=lambda x: _nodemand_label if x == "ìˆ˜ìš”0" else x,
        key="health_bucket_filter",
    )
    if not selected_buckets:
        selected_buckets = bucket_options
    display_health = health[health["bucket"].isin(selected_buckets)].copy()
    if (sku_search_term or "").strip():
        term = (sku_search_term or "").strip().lower()
        display_health = display_health[
            display_health["sku"].astype(str).str.lower().str.contains(term, na=False)
            | display_health["sku_name"].astype(str).str.lower().str.contains(term, na=False)
        ]
    display_health = display_health.sort_values(["_bucket_order", "coverage_days"], ascending=[True, True], na_position="last")
    display_health = display_health[
        ["sku", "sku_name", "category", "warehouse", "onhand_qty", "demand_30d", "avg_daily_demand_Nd", "coverage_days", "bucket"]
    ].drop(columns=["_bucket_order"], errors="ignore")
    display_health["bucket"] = display_health["bucket"].replace("ìˆ˜ìš”0", _nodemand_label)
    # Formatted copy for display (qty comma, days 1 decimal)
    display_health_fmt = display_health.copy()
    display_health_fmt["onhand_qty"] = display_health_fmt["onhand_qty"].apply(lambda v: fmt_qty(v))
    display_health_fmt["demand_30d"] = display_health_fmt["demand_30d"].apply(lambda v: fmt_qty(v))
    display_health_fmt["avg_daily_demand_Nd"] = display_health_fmt["avg_daily_demand_Nd"].apply(lambda v: fmt_qty(v))
    display_health_fmt["coverage_days"] = display_health_fmt["coverage_days"].apply(lambda v: fmt_days(v) if pd.notna(v) else "â€”")
    st.dataframe(display_health_fmt, use_container_width=True, hide_index=True)
    st.download_button("ì¬ê³  ì ì •ì„± ëª©ë¡ ë‚´ë ¤ë°›ê¸° (CSV)", data=display_health.to_csv(index=False).encode("utf-8-sig"), file_name="health_list.csv", mime="text/csv", key="dl_health")

with tab_stockout:
    st.subheader("í’ˆì ˆ ìœ„í—˜")
    st.caption("Nì¼ ì´ë‚´ í’ˆì ˆ ì˜ˆìƒ SKUÂ·ì˜ˆìƒ í’ˆì ˆì¼Â·ìœ„í—˜ë“±ê¸‰. Criticalë¶€í„° í™•ì¸í•œ ë’¤ **ë°œì£¼Â·ì¡°ì¹˜** íƒ­ì—ì„œ ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ í™•ì¸í•˜ì„¸ìš”.")
    if summary_stockout_cnt > 0:
        st.info("**ë°”ë¡œ í•  ì¼:** ì•„ë˜ ëª©ë¡ì—ì„œ Critical SKUë¥¼ í™•ì¸í•œ ë’¤ **ë°œì£¼Â·ì¡°ì¹˜** íƒ­ì—ì„œ ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.markdown("**ì¡°íšŒ ì¡°ê±´**")
    risk_basis_opts = ["ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )", "ì˜ˆì¸¡ ê¸°ì¤€(horizon)"]
    risk_basis = st.selectbox(
        "í’ˆì ˆ ì‚°ì • ê¸°ì¤€",
        options=risk_basis_opts,
        index=risk_basis_opts.index(st.session_state.get("risk_basis", "ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )")) if st.session_state.get("risk_basis", "ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )") in risk_basis_opts else 0,
        key="risk_basis",
    )
    stockout_within_opts = [7, 14, 21, 30, 60]
    stockout_within_days = st.selectbox(
        "í’ˆì ˆ ìœ„í—˜ ê¸°ì¤€(Nì¼ ë¯¸ë§Œ)",
        options=stockout_within_opts,
        index=stockout_within_opts.index(st.session_state.get("risk_stockout_within_days", 14)) if st.session_state.get("risk_stockout_within_days", 14) in stockout_within_opts else 1,
        format_func=lambda x: f"{x}ì¼ ë¯¸ë§Œ",
        key="risk_stockout_within_days",
    )
    risk_level_filter = st.selectbox(
        "ìœ„í—˜ë“±ê¸‰",
        options=["ì „ì²´", "Critical", "High", "Medium", "Low"],
        key="risk_level_filter",
    )

    # í’ˆì ˆ ë¦¬ìŠ¤í¬ SQL (íƒ­ ë‚´ ì‹¤í–‰, ê³¼ê±° 14ì¼ ê¸°ì¤€)
    risk_sql = f"""
    WITH base_sku AS (
      SELECT m.sku, m.sku_name, m.category
      FROM sku_master m
      WHERE 1=1
      {base_where}
    ),
    latest_inv AS (
      SELECT sku, warehouse, onhand_qty
      FROM inventory_daily
      WHERE date = '{latest_date}'
      {_inv_wh_where(wh)}
    ),
    avg_daily_demand AS (
      SELECT sku, AVG(demand_qty) AS avg_daily_demand_14d
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    demand_7d_cte AS (
      SELECT sku, SUM(demand_qty) AS demand_7d
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 7 DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    base AS (
      SELECT
        b.sku, b.sku_name, b.category,
        li.warehouse,
        COALESCE(li.onhand_qty, 0) AS onhand_qty,
        COALESCE(ad.avg_daily_demand_14d, 0) AS avg_daily_demand_14d,
        COALESCE(d7.demand_7d, 0) AS demand_7d,
        CASE WHEN COALESCE(ad.avg_daily_demand_14d, 0) = 0 THEN NULL
          ELSE ROUND(COALESCE(li.onhand_qty, 0) / ad.avg_daily_demand_14d, 1) END AS coverage_days
      FROM base_sku b
      LEFT JOIN latest_inv li ON b.sku = li.sku
      LEFT JOIN avg_daily_demand ad ON b.sku = ad.sku
      LEFT JOIN demand_7d_cte d7 ON b.sku = d7.sku
    )
    SELECT
      sku, sku_name, category, warehouse,
      onhand_qty, avg_daily_demand_14d, demand_7d, coverage_days,
      CASE WHEN coverage_days IS NOT NULL THEN date_add('{latest_date}'::DATE, CAST(CEIL(coverage_days) AS INTEGER)) ELSE NULL END AS estimated_stockout_date
    FROM base
    """
    risk = con.execute(risk_sql).fetchdf()

    def assign_risk_level(days):
        if pd.isna(days):
            return "Low"
        if days < 3:
            return "Critical"
        if days < 7:
            return "High"
        if days < 14:
            return "Medium"
        return "Low"

    risk["risk_level"] = risk["coverage_days"].apply(assign_risk_level)
    risk["priority_score"] = risk.apply(
        lambda r: (r["demand_7d"] or 0) / max((r["coverage_days"] or 1), 1), axis=1
    )

    use_forecast_risk = risk_basis == "ì˜ˆì¸¡ ê¸°ì¤€(horizon)" and not forecast_metrics_df.empty
    if use_forecast_risk:
        sku_info = risk[["sku", "sku_name", "category", "warehouse", "onhand_qty"]].drop_duplicates("sku")
        risk_f = forecast_metrics_df.merge(sku_info, on="sku", how="inner", suffixes=("", "_y"))
        risk_f = risk_f[[c for c in risk_f.columns if not c.endswith("_y")]]
        risk_f = risk_f.rename(columns={
            "forecast_dos": "coverage_days",
            "stockout_date_forecast": "estimated_stockout_date",
            "forecast_avg_daily": "avg_daily_demand_14d",
            "forecast_demand_next7": "demand_7d",
        })
        risk_f["risk_level"] = risk_f["coverage_days"].apply(assign_risk_level)
        risk_f["priority_score"] = risk_f.apply(
            lambda r: (r["demand_7d"] or 0) / max((r["coverage_days"] or 1), 1), axis=1
        )
        risk = risk_f

    risk_filtered = risk[
        (risk["coverage_days"].notna()) & (risk["coverage_days"] < stockout_within_days)
    ].copy()
    if risk_level_filter != "ì „ì²´":
        risk_filtered = risk_filtered[risk_filtered["risk_level"] == risk_level_filter]

    # KPI 3ê°œ: ë¦¬ìŠ¤í¬ SKU ìˆ˜, ê°€ì¥ ë¹ ë¥¸ ì˜ˆìƒ í’ˆì ˆì¼, ë¦¬ìŠ¤í¬ ìˆ˜ìš”(ìµœê·¼ 7ì¼/ì˜ˆì¸¡ 7ì¼ í•©)
    risk_sku_cnt = len(risk_filtered)
    earliest_stockout = risk_filtered["estimated_stockout_date"].min() if not risk_filtered.empty and risk_filtered["estimated_stockout_date"].notna().any() else None
    demand_col = "demand_7d"
    risk_demand_7d = int(risk_filtered[demand_col].sum()) if not risk_filtered.empty and demand_col in risk_filtered.columns else 0

    col1, col2, col3 = st.columns(3)
    col1.metric("í’ˆì ˆ ìœ„í—˜ SKU ìˆ˜", fmt_qty(risk_sku_cnt))
    col2.metric("ê°€ì¥ ë¹ ë¥¸ ì˜ˆìƒ í’ˆì ˆì¼" + (" (ì˜ˆì¸¡ ê¸°ì¤€)" if use_forecast_risk else ""), fmt_date(earliest_stockout) if earliest_stockout is not None and pd.notna(earliest_stockout) else "â€”")
    col3.metric("ìœ„í—˜ êµ¬ê°„ ìˆ˜ìš”(7ì¼)" + (" ì˜ˆì¸¡" if use_forecast_risk else " ì‹¤ì "), fmt_qty(risk_demand_7d))

    st.markdown("**í’ˆì ˆ ìœ„í—˜ SKU ëª©ë¡**" + (" (ì˜ˆì¸¡ ê¸°ì¤€)" if use_forecast_risk else ""))
    risk_for_table = risk_filtered if show_only_exceptions else risk
    if risk_level_filter != "ì „ì²´" and show_only_exceptions:
        risk_for_table = risk_for_table[risk_for_table["risk_level"] == risk_level_filter]
    display_cols = [
        "sku", "sku_name", "warehouse",
        "coverage_days", "estimated_stockout_date",
        "onhand_qty", "avg_daily_demand_14d", "demand_7d",
        "risk_level", "priority_score",
    ]
    display_cols = [c for c in display_cols if c in risk_for_table.columns]
    display_risk = risk_for_table[display_cols].copy()
    if (sku_search_term or "").strip():
        term = (sku_search_term or "").strip().lower()
        display_risk = display_risk[
            display_risk["sku"].astype(str).str.lower().str.contains(term, na=False)
            | display_risk["sku_name"].astype(str).str.lower().str.contains(term, na=False)
        ]
    display_risk = display_risk.rename(columns={
        "coverage_days": "ì»¤ë²„ë¦¬ì§€(DOS)",
        "estimated_stockout_date": "ì˜ˆìƒ í’ˆì ˆì¼",
        "avg_daily_demand_14d": "avg_daily_demand",
    })
    sort_options = ["ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœ", "ìš°ì„ ìˆœìœ„ ì ìˆ˜ ë†’ì€ ìˆœ", "ì»¤ë²„ë¦¬ì§€(DOS) ì§§ì€ ìˆœ", "SKU"]
    risk_sort = st.selectbox("ì •ë ¬ ê¸°ì¤€", options=sort_options, index=0, key="risk_sort_by")
    if risk_sort == "ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœ":
        sort_col = "ì˜ˆìƒ í’ˆì ˆì¼"
        if sort_col in display_risk.columns:
            display_risk = display_risk.sort_values([sort_col, "priority_score"], ascending=[True, False], na_position="last")
    elif risk_sort == "ìš°ì„ ìˆœìœ„ ì ìˆ˜ ë†’ì€ ìˆœ" and "priority_score" in display_risk.columns:
        display_risk = display_risk.sort_values("priority_score", ascending=False, na_position="last")
    elif risk_sort == "ì»¤ë²„ë¦¬ì§€(DOS) ì§§ì€ ìˆœ" and "ì»¤ë²„ë¦¬ì§€(DOS)" in display_risk.columns:
        display_risk = display_risk.sort_values("ì»¤ë²„ë¦¬ì§€(DOS)", ascending=True, na_position="last")
    elif risk_sort == "SKU":
        display_risk = display_risk.sort_values("sku", ascending=True)
    date_col = "ì˜ˆìƒ í’ˆì ˆì¼"
    display_risk_fmt = display_risk.copy()
    for qty_col in ["onhand_qty", "avg_daily_demand", "demand_7d"]:
        if qty_col in display_risk_fmt.columns:
            display_risk_fmt[qty_col] = display_risk_fmt[qty_col].apply(lambda v: fmt_qty(v))
    if "ì»¤ë²„ë¦¬ì§€(DOS)" in display_risk_fmt.columns:
        display_risk_fmt["ì»¤ë²„ë¦¬ì§€(DOS)"] = display_risk_fmt["ì»¤ë²„ë¦¬ì§€(DOS)"].apply(lambda v: fmt_days(v) if pd.notna(v) else "â€”")
    if date_col in display_risk_fmt.columns:
        display_risk_fmt[date_col] = display_risk_fmt[date_col].apply(lambda v: fmt_date(v) if pd.notna(v) else "â€”")
    st.dataframe(display_risk_fmt, use_container_width=True, hide_index=True)
    st.download_button("í’ˆì ˆ ìœ„í—˜ ëª©ë¡ ë‚´ë ¤ë°›ê¸° (CSV)", data=display_risk.to_csv(index=False).encode("utf-8-sig"), file_name="risk_list.csv", mime="text/csv", key="dl_risk")
    st.caption("ìš°ì„ ìˆœìœ„ ì ìˆ˜ = 7ì¼ ìˆ˜ìš” Ã· ì»¤ë²„ë¦¬ì§€(DOS). " + ("ì˜ˆìƒ í’ˆì ˆì¼ = ëˆ„ì  ì˜ˆì¸¡ ìˆ˜ìš”ë¡œ ì¬ê³  ì†Œì§„ë˜ëŠ” ì²« ë‚ (ì˜ˆì¸¡ ê¸°ì¤€)." if use_forecast_risk else "ì˜ˆìƒ í’ˆì ˆì¼ = ê¸°ì¤€ì¼ + DOS(ì˜¬ë¦¼)ì¼(ì‹¤ì  ê¸°ì¤€)."))

with tab_actions:
    st.subheader("ë°œì£¼Â·ì¡°ì¹˜")
    st.caption("ì •ì±…(ë¦¬ë“œíƒ€ì„Â·ëª©í‘œ ì»¤ë²„ë¦¬ì§€Â·ì•ˆì „ì¬ê³ Â·ìµœì†Œë°œì£¼ìˆ˜ëŸ‰)ì— ë”°ë¥¸ ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰. ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœìœ¼ë¡œ ì¡°ì¹˜í•˜ì„¸ìš”.")
    if summary_stockout_cnt > 0:
        st.info("**ë°”ë¡œ í•  ì¼:** ì •ë ¬ ê¸°ì¤€ì„ ì˜ˆìƒ í’ˆì ˆì¼ë¡œ ë‘ê³  Critical SKUë¶€í„° ë°œì£¼í•˜ì„¸ìš”.")
    st.markdown("**ë°œì£¼ ê¸°ì¤€**")
    actions_basis_opts = ["ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )", "ì˜ˆì¸¡ ê¸°ì¤€(horizon)"]
    actions_basis = st.selectbox(
        "ë°œì£¼ ì‚°ì • ê¸°ì¤€",
        options=actions_basis_opts,
        index=actions_basis_opts.index(st.session_state.get("actions_basis", "ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )")) if st.session_state.get("actions_basis", "ì‹¤ì  ê¸°ì¤€(14ì¼ í‰ê· )") in actions_basis_opts else 0,
        key="actions_basis",
    )
    use_forecast_actions = actions_basis == "ì˜ˆì¸¡ ê¸°ì¤€(horizon)" and not forecast_metrics_df.empty

    st.divider()
    st.markdown("**ì •ì±… íŒŒë¼ë¯¸í„°**")
    col_lt, col_tc, col_ss, col_moq = st.columns(4)
    with col_lt:
        lead_time_days = st.number_input("ë¦¬ë“œíƒ€ì„(ì¼)", min_value=0, value=7, step=1, key="lead_time_days")
    with col_tc:
        target_cover_days = st.number_input("ëª©í‘œ ì»¤ë²„ë¦¬ì§€(ì¼)", min_value=0, value=14, step=1, key="target_cover_days")
    with col_ss:
        safety_stock_days = st.number_input("ì•ˆì „ì¬ê³ (ì¼)", min_value=0, value=3, step=1, key="safety_stock_days")
    with col_moq:
        moq = st.number_input("ìµœì†Œë°œì£¼ìˆ˜ëŸ‰(MOQ, 0=ë¯¸ì ìš©)", min_value=0, value=0, step=1, key="moq")

    # ë°œì£¼ base SQL (íƒ­ ë‚´ ì‹¤í–‰, ê³¼ê±° 14ì¼ ê¸°ì¤€)
    actions_sql = f"""
    WITH base_sku AS (
      SELECT m.sku, m.sku_name, m.category
      FROM sku_master m
      WHERE 1=1
      {base_where}
    ),
    latest_inv AS (
      SELECT sku, warehouse, onhand_qty
      FROM inventory_daily
      WHERE date = '{latest_date}'
      {_inv_wh_where(wh)}
    ),
    avg_daily_demand AS (
      SELECT sku, AVG(demand_qty) AS avg_daily_demand_14d
      FROM demand_daily
      WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY AND date <= '{latest_date}'
      GROUP BY sku
    ),
    base AS (
      SELECT
        b.sku, b.sku_name, b.category,
        li.warehouse,
        COALESCE(li.onhand_qty, 0) AS onhand_qty,
        COALESCE(ad.avg_daily_demand_14d, 0) AS avg_daily_demand_14d,
        ROUND(COALESCE(ad.avg_daily_demand_14d, 0) * 10, 0) AS reorder_point,
        CASE WHEN COALESCE(ad.avg_daily_demand_14d, 0) = 0 THEN NULL
          ELSE ROUND(COALESCE(li.onhand_qty, 0) / ad.avg_daily_demand_14d, 1) END AS coverage_days
      FROM base_sku b
      LEFT JOIN latest_inv li ON b.sku = li.sku
      LEFT JOIN avg_daily_demand ad ON b.sku = ad.sku
    )
    SELECT
      sku, sku_name, category, warehouse,
      onhand_qty, reorder_point, avg_daily_demand_14d, coverage_days,
      CASE WHEN coverage_days IS NOT NULL THEN date_add('{latest_date}'::DATE, CAST(CEIL(coverage_days) AS INTEGER)) ELSE NULL END AS estimated_stockout_date
    FROM base
    """
    actions_df = con.execute(actions_sql).fetchdf()
    onhand = pd.to_numeric(actions_df["onhand_qty"], errors="coerce").fillna(0)
    avg_d = pd.to_numeric(actions_df["avg_daily_demand_14d"], errors="coerce").fillna(0)
    total_days = lead_time_days + target_cover_days + safety_stock_days
    target_stock = (avg_d * total_days).round(0).astype(int)
    recommended_order_qty = (target_stock - onhand).clip(lower=0).astype(int)
    if moq > 0:
        recommended_order_qty = recommended_order_qty.where(recommended_order_qty <= 0, recommended_order_qty.clip(lower=moq)).astype(int)
    actions_base = actions_df.copy()
    actions_base["target_stock"] = target_stock
    actions_base["recommended_order_qty"] = recommended_order_qty

    # ì˜ˆì¸¡ ê¸°ë°˜ì¼ ë•Œ: lead_time_forecast + (forecast_avg_daily * target_cover_days) + safety_stock_forecast
    if use_forecast_actions:
        latest_dt = pd.to_datetime(latest_date)
        lead_cut = latest_dt + pd.Timedelta(days=lead_time_days)
        f_daily = forecast_daily.copy()
        f_daily["date"] = pd.to_datetime(f_daily["date"])
        f_lead = f_daily[f_daily["date"] <= lead_cut].groupby("sku")["forecast_qty"].sum().reindex(actions_base["sku"]).fillna(0)
        f_metrics = forecast_metrics_df[["sku", "forecast_avg_daily", "forecast_dos", "stockout_date_forecast"]].drop_duplicates("sku")
        actions_base = actions_base.merge(f_metrics, on="sku", how="left", suffixes=("", "_f"))
        actions_base["lead_time_forecast"] = actions_base["sku"].map(lambda s: f_lead.get(s, 0) if s in f_lead.index else 0)
        fa = actions_base["forecast_avg_daily"].fillna(0)
        lt_f = actions_base["lead_time_forecast"].fillna(0)
        target_stock = (lt_f + fa * target_cover_days + fa * safety_stock_days).round(0).astype(int)
        onhand = pd.to_numeric(actions_base["onhand_qty"], errors="coerce").fillna(0)
        recommended_order_qty = (target_stock - onhand).clip(lower=0).astype(int)
        if moq > 0:
            recommended_order_qty = recommended_order_qty.where(recommended_order_qty <= 0, recommended_order_qty.clip(lower=moq)).astype(int)
        actions_base["target_stock"] = target_stock
        actions_base["recommended_order_qty"] = recommended_order_qty
        actions_base["coverage_days"] = actions_base["forecast_dos"]
        actions_base["estimated_stockout_date"] = actions_base["stockout_date_forecast"]
        actions_base["avg_daily_demand_14d"] = actions_base["forecast_avg_daily"]
        actions_base = actions_base.drop(columns=["forecast_avg_daily", "forecast_dos", "stockout_date_forecast", "lead_time_forecast"], errors="ignore")

    # reason MECE: ì˜ˆì¸¡ ì‹œ "ì˜ˆì¸¡ í’ˆì ˆ ì„ë°•" / "ë¦¬ë“œíƒ€ì„ ìˆ˜ìš” ëŒ€ë¹„ ë¶€ì¡±" / "ì •ì±… ë³´ì¶©". ê³¼ê±° ì‹œ ê¸°ì¡´ ìœ ì§€.
    def assign_reason_past(row):
        if pd.notna(row["coverage_days"]) and row["coverage_days"] < target_cover_days:
            return "ì¦‰ì‹œìœ„í—˜(DOS<ëª©í‘œì»¤ë²„)"
        if row["onhand_qty"] < row["target_stock"]:
            return "ì •ì±…ë³´ì¶©(ROP ë¯¸ë‹¬)"
        return "ê¸°íƒ€"

    def assign_reason_forecast(row):
        if pd.notna(row["coverage_days"]) and row["coverage_days"] < target_cover_days:
            return "ì˜ˆì¸¡ í’ˆì ˆ ì„ë°•"
        if row["onhand_qty"] < row["target_stock"]:
            return "ë¦¬ë“œíƒ€ì„ ìˆ˜ìš” ëŒ€ë¹„ ë¶€ì¡±"
        return "ì •ì±… ë³´ì¶©"

    actions_base["reason"] = actions_base.apply(
        assign_reason_forecast if use_forecast_actions else assign_reason_past, axis=1
    )
    actions_display = actions_base[actions_base["recommended_order_qty"] > 0].copy()
    actions_display = actions_display.sort_values(
        ["estimated_stockout_date", "recommended_order_qty"],
        ascending=[True, False],
        na_position="last",
    )

    # reason ë©€í‹°ì…€ë ‰íŠ¸; when show_only_exceptions OFF, default to all reasons
    reason_options = (
        ["ì˜ˆì¸¡ í’ˆì ˆ ì„ë°•", "ë¦¬ë“œíƒ€ì„ ìˆ˜ìš” ëŒ€ë¹„ ë¶€ì¡±", "ì •ì±… ë³´ì¶©"]
        if use_forecast_actions
        else ["ì¦‰ì‹œìœ„í—˜(DOS<ëª©í‘œì»¤ë²„)", "ì •ì±…ë³´ì¶©(ROP ë¯¸ë‹¬)", "ê¸°íƒ€"]
    )
    default_reasons = reason_options[:2] if show_only_exceptions else reason_options
    selected_reasons = st.multiselect(
        "ì¶”ì²œ ì‚¬ìœ ",
        options=reason_options,
        default=default_reasons,
        key="actions_reason_filter",
    )
    if not selected_reasons:
        selected_reasons = reason_options
    actions_filtered = actions_display[actions_display["reason"].isin(selected_reasons)].copy()
    if not show_only_exceptions:
        actions_for_table = actions_base[actions_base["reason"].isin(selected_reasons)].copy()
    else:
        actions_for_table = actions_filtered.copy()
    if (sku_search_term or "").strip():
        term = (sku_search_term or "").strip().lower()
        actions_for_table = actions_for_table[
            actions_for_table["sku"].astype(str).str.lower().str.contains(term, na=False)
            | actions_for_table["sku_name"].astype(str).str.lower().str.contains(term, na=False)
        ]

    st.divider()
    st.markdown("**ê¶Œì¥ ë°œì£¼ ëª©ë¡**" + (" (ì˜ˆì¸¡ ê¸°ì¤€)" if use_forecast_actions else ""))
    sort_options_act = ["ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœ", "ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ ë§ì€ ìˆœ", "ì»¤ë²„ë¦¬ì§€(DOS) ì§§ì€ ìˆœ", "SKU"]
    act_sort = st.selectbox("ì •ë ¬ ê¸°ì¤€", options=sort_options_act, index=0, key="actions_sort_by")
    date_col_act = "estimated_stockout_date"
    if act_sort == "ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœ":
        actions_for_table = actions_for_table.sort_values([date_col_act, "recommended_order_qty"], ascending=[True, False], na_position="last")
    elif act_sort == "ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ ë§ì€ ìˆœ":
        actions_for_table = actions_for_table.sort_values("recommended_order_qty", ascending=False, na_position="last")
    elif act_sort == "ì»¤ë²„ë¦¬ì§€(DOS) ì§§ì€ ìˆœ":
        actions_for_table = actions_for_table.sort_values("coverage_days", ascending=True, na_position="last")
    elif act_sort == "SKU":
        actions_for_table = actions_for_table.sort_values("sku", ascending=True)
    display_cols = ["sku", "sku_name", "category", "warehouse", "reason", "estimated_stockout_date", "onhand_qty", "avg_daily_demand_14d", "coverage_days", "target_stock", "recommended_order_qty"]
    display_cols = [c for c in display_cols if c in actions_for_table.columns]
    out = actions_for_table[display_cols].copy()
    out = out.rename(columns={
        "estimated_stockout_date": "ì˜ˆìƒ í’ˆì ˆì¼",
        "coverage_days": "ì»¤ë²„ë¦¬ì§€(DOS)",
    })
    out["onhand_qty"] = out["onhand_qty"].apply(lambda x: fmt_qty(x))
    out["avg_daily_demand_14d"] = out["avg_daily_demand_14d"].apply(lambda x: fmt_days(x) if pd.notna(x) else "â€”")
    out["ì»¤ë²„ë¦¬ì§€(DOS)"] = out["ì»¤ë²„ë¦¬ì§€(DOS)"].apply(lambda x: fmt_days(x) if pd.notna(x) else "â€”")
    out["target_stock"] = out["target_stock"].apply(lambda x: fmt_qty(x))
    out["recommended_order_qty"] = out["recommended_order_qty"].apply(lambda x: fmt_qty(x))
    date_col_out = "ì˜ˆìƒ í’ˆì ˆì¼"
    if date_col_out in out.columns:
        out[date_col_out] = out[date_col_out].apply(lambda v: fmt_date(v) if pd.notna(v) else "â€”")
    st.dataframe(out, use_container_width=True, hide_index=True)
    st.download_button("ë°œì£¼Â·ì¡°ì¹˜ ëª©ë¡ ë‚´ë ¤ë°›ê¸° (CSV)", data=actions_for_table.to_csv(index=False).encode("utf-8-sig"), file_name="actions_list.csv", mime="text/csv", key="dl_actions")
    st.caption("ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ì´ 0ë³´ë‹¤ í° SKUë§Œ í‘œì‹œ(ì˜ˆì™¸ë§Œ ë³´ê¸° ON ì‹œ). ì •ë ¬: ì˜ˆìƒ í’ˆì ˆì¼ ë¹ ë¥¸ ìˆœ â†’ ê¶Œì¥ ë°œì£¼ìˆ˜ëŸ‰ ë§ì€ ìˆœ.")

with tab_movements:
    st.subheader("ì…ì¶œê³  ì¶”ì ")
    st.caption("ê¸°ê°„ ë‚´ ì…ê³ Â·ì¶œê³ Â·ìˆœì¦ê°ê³¼ ê±°ë˜ ìƒì„¸. ì¬ê³  ë³€ë™ ì›ì¸ íŒŒì•…Â·ëŒ€ëŸ‰ ê±°ë˜ í™•ì¸ì— í™œìš©í•˜ì„¸ìš”.")
    if inv_txn is None or len(inv_txn) == 0:
        st.info("ì…ì¶œê³  ê±°ë˜(inventory_txn) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ ì ì¬í•˜ë©´ ì…ì¶œê³  ì°¨íŠ¸ì™€ ê±°ë˜ ëª©ë¡ì´ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        # ê¸°ê°„ í•„í„°: íƒ­ ë‚´ë¶€ì—ì„œ ì„ íƒ (mv_range_days, ê¸°ë³¸ 60)
        mov_range_days = st.selectbox(
            "ë¶„ì„ ê¸°ê°„(ì¼)",
            options=[7, 14, 30, 60, 90],
            index=[7, 14, 30, 60, 90].index(st.session_state.get("mov_range_days", 60)) if st.session_state.get("mov_range_days", 60) in [7, 14, 30, 60, 90] else 3,
            format_func=lambda x: f"{x}ì¼",
            key="mov_range_days",
        )

        # ì…ì¶œê³  ì§‘ê³„ (dt/qty ê°•ì œ ìºìŠ¤íŒ…, mov_range_days)
        txn_trend_sql = f"""
        WITH filtered AS (
          SELECT
            CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE) AS dt,
            TRY_CAST(t.qty AS DOUBLE) AS qty
          FROM inventory_txn t
          WHERE CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE)
                BETWEEN '{latest_date}'::DATE - INTERVAL {mov_range_days} DAY AND '{latest_date}'::DATE
            {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
            {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
            {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
        )
        SELECT
          dt AS date,
          SUM(CASE WHEN COALESCE(qty, 0) > 0 THEN qty ELSE 0 END) AS in_qty,
          SUM(CASE WHEN COALESCE(qty, 0) < 0 THEN ABS(qty) ELSE 0 END) AS out_qty
        FROM filtered
        GROUP BY dt
        ORDER BY dt
        """
        txn_trend = con.execute(txn_trend_sql).fetchdf()
        if not txn_trend.empty:
            txn_trend["net_qty"] = txn_trend["in_qty"].fillna(0) - txn_trend["out_qty"].fillna(0)
        sum_in = txn_trend["in_qty"].fillna(0).sum() if not txn_trend.empty else 0
        sum_out = txn_trend["out_qty"].fillna(0).sum() if not txn_trend.empty else 0
        sum_net = sum_in - sum_out

        # í•„í„° ë°˜ì˜ í›„ íŠ¸ëœì­ì…˜ row ìˆ˜
        txn_count_sql = f"""
        SELECT COUNT(*) AS cnt
        FROM inventory_txn t
        WHERE CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE)
              BETWEEN '{latest_date}'::DATE - INTERVAL {mov_range_days} DAY AND '{latest_date}'::DATE
          {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
          {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
          {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
        """
        txn_row_count = int(con.execute(txn_count_sql).fetchone()[0])

        st.markdown("**ì§‘ê³„ ìš”ì•½**")
        col_diag1, col_diag2, col_diag3, col_diag4 = st.columns(4)
        col_diag1.metric("ê±´ìˆ˜", f"{txn_row_count:,}ê±´")
        col_diag2.metric("ì…ê³  í•©ê³„", f"{sum_in:,.0f}")
        col_diag3.metric("ì¶œê³  í•©ê³„", f"{sum_out:,.0f}")
        col_diag4.metric("ìˆœì¦ê°(ì…ê³ âˆ’ì¶œê³ )", f"{sum_net:,.0f}")

        # ì°¨íŠ¸ 3ê°œ: ì…ê³  bar, ì¶œê³  bar, ìˆœë³€í™”(net) line
        has_rows = not txn_trend.empty
        if not has_rows:
            st.warning("í•„í„° ì¡°ê±´ì—ì„œ ì§‘ê³„ëœ ì¼ìê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„Â·ì°½ê³ Â·SKUÂ·ì¹´í…Œê³ ë¦¬ í•„í„°ë¥¼ ì™„í™”í•˜ê±°ë‚˜, í•´ë‹¹ ê¸°ê°„ì— ê±°ë˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            col_in, col_out = st.columns(2)
            with col_in:
                fig_in = px.bar(txn_trend, x="date", y="in_qty", title=f"ì…ê³ (IN) â€” ìµœê·¼ {mov_range_days}ì¼")
                fig_in.update_layout(xaxis_title="ì¼ì", yaxis_title="ì…ê³  ìˆ˜ëŸ‰")
                fig_in.update_xaxes(tickformat="%Y-%m-%d")
                fig_in.update_yaxes(tickformat=",.0f")
                fig_in = apply_plotly_theme(fig_in)
                st.plotly_chart(fig_in, use_container_width=True)
            with col_out:
                fig_out = px.bar(txn_trend, x="date", y="out_qty", title=f"ì¶œê³ (OUT) â€” ìµœê·¼ {mov_range_days}ì¼")
                fig_out.update_layout(xaxis_title="ì¼ì", yaxis_title="ì¶œê³  ìˆ˜ëŸ‰")
                fig_out.update_xaxes(tickformat="%Y-%m-%d")
                fig_out.update_yaxes(tickformat=",.0f")
                fig_out = apply_plotly_theme(fig_out)
                st.plotly_chart(fig_out, use_container_width=True)
            fig_net = px.line(txn_trend, x="date", y="net_qty", title=f"ìˆœë³€í™”(Net = ì…ê³ âˆ’ì¶œê³ ) â€” ìµœê·¼ {mov_range_days}ì¼")
            fig_net.update_layout(xaxis_title="ì¼ì", yaxis_title="ìˆœë³€í™” ìˆ˜ëŸ‰")
            fig_net.update_xaxes(tickformat="%Y-%m-%d")
            fig_net.update_yaxes(tickformat=",.0f")
            add_ref_hline(fig_net, 0, "0", line_dash="dash", line_color="gray")
            fig_net = apply_plotly_theme(fig_net)
            st.plotly_chart(fig_net, use_container_width=True)

        # í…Œì´ë¸” 2ê°œ ë·°: ìµœì‹  200ê±´ / qty ì ˆëŒ€ê°’ Top 50 (í° ê±°ë˜ ì›ì¸)
        txn_list_sql = f"""
        SELECT
          t.txn_datetime,
          CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE) AS dt,
          t.sku, t.warehouse, t.txn_type,
          TRY_CAST(t.qty AS DOUBLE) AS qty,
          t.ref_id, t.reason_code
        FROM inventory_txn t
        WHERE 1=1
          {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
          {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
          {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
        ORDER BY t.txn_datetime DESC
        LIMIT 200
        """
        txn_list = con.execute(txn_list_sql).fetchdf()
        txn_top50_sql = f"""
        SELECT
          t.txn_datetime,
          CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE) AS dt,
          t.sku, t.warehouse, t.txn_type,
          TRY_CAST(t.qty AS DOUBLE) AS qty,
          ABS(TRY_CAST(t.qty AS DOUBLE)) AS abs_qty,
          t.ref_id, t.reason_code
        FROM inventory_txn t
        WHERE 1=1
          {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
          {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
          {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
        ORDER BY abs_qty DESC
        LIMIT 50
        """
        txn_top50 = con.execute(txn_top50_sql).fetchdf()
        if not txn_top50.empty and "abs_qty" in txn_top50.columns:
            txn_top50 = txn_top50.drop(columns=["abs_qty"], errors="ignore")

        view_txn = st.radio("ëª©ë¡ ë³´ê¸°", ["ìµœì‹  200ê±´", "ìˆ˜ëŸ‰ í° ìˆœ ìƒìœ„ 50ê±´(ì£¼ìš” ê±°ë˜)"], horizontal=True, key="mov_view")
        if view_txn == "ìµœì‹  200ê±´":
            st.markdown("**ê±°ë˜ ëª©ë¡ (ìµœì‹  200ê±´)**")
            if txn_list.empty:
                st.caption("í•„í„° ì¡°ê±´ì— ë§ëŠ” ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(txn_list, use_container_width=True)
        else:
            st.markdown("**ìˆ˜ëŸ‰ í° ìˆœ ìƒìœ„ 50ê±´ (ì£¼ìš” ê±°ë˜)**")
            if txn_top50.empty:
                st.caption("í•„í„° ì¡°ê±´ì— ë§ëŠ” ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(txn_top50, use_container_width=True)
        st.caption("ì¼ì = ê±°ë˜ì¼ ê¸°ì¤€. ìˆ˜ëŸ‰: ì…ê³ (+) / ì¶œê³ (âˆ’).")
