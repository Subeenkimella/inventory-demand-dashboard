import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px

st.set_page_config(page_title="ìž¬ê³  ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", layout="wide")

def apply_plotly_theme(fig):
    fig.update_layout(
        template="plotly_white",
        font=dict(size=13),
        title_font=dict(size=16),
        legend_font=dict(size=12),
        xaxis=dict(showgrid=True, gridcolor="#e5e5e5"),
        yaxis=dict(
            showgrid=True,
            gridcolor="#e5e5e5",
            tickformat=",.0f",
        ),
        margin=dict(l=40, r=20, t=60, b=40),
    )
    return fig

@st.cache_data
def load_data():
    sku = pd.read_csv("sku_master.csv")
    demand = pd.read_csv("demand_daily.csv", parse_dates=["date"])
    inv = pd.read_csv("inventory_daily.csv", parse_dates=["date"])
    try:
        inv_txn = pd.read_csv("inventory_txn.csv", parse_dates=["date", "txn_datetime"])
    except FileNotFoundError:
        inv_txn = pd.DataFrame(columns=["txn_datetime", "date", "sku", "warehouse", "txn_type", "qty", "ref_id", "reason_code"])
    return sku, demand, inv, inv_txn

sku, demand, inv, inv_txn = load_data()

# DuckDB in-memory (SQL engine)
con = duckdb.connect(database=":memory:")
con.register("sku_master", sku)
con.register("demand_daily", demand)
con.register("inventory_daily", inv)
if inv_txn is not None and len(inv_txn) > 0:
    con.register("inventory_txn", inv_txn)

st.markdown("""
<style>
    h1 { font-size: 2.08rem !important; }
</style>
""", unsafe_allow_html=True)
st.title("ðŸ“¦ ìž¬ê³ Â·ìˆ˜ìš” ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
st.caption("ìƒ˜í”Œ CSV ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ SQL(DuckDB)ë¡œ KPIë¥¼ ê³„ì‚°")

# Latest snapshot date
latest_date = con.execute("SELECT MAX(date) FROM inventory_daily").fetchone()[0]

category_map = {
  "ALL": "ì „ì²´",
  "Motor": "ëª¨í„°",
  "Brake": "ë¸Œë ˆì´í¬",
  "Steering": "ìŠ¤í‹°ì–´ë§",
  "Sensor": "ì„¼ì„œ",
}

warehouse_map = {
  "ALL" : "ì „ì²´",
  "WH-1": "ì°½ê³  1",
  "WH-2": "ì°½ê³  2",
}

plant_map = {
  "ALL": "ì „ì²´",
  "PLANT-A": "ê³µìž¥ A",
  "PLANT-B": "ê³µìž¥ B",
}

# Sidebar filters
st.sidebar.header("í•„í„°")
cat = st.sidebar.selectbox(
    "ì¹´í…Œê³ ë¦¬",
    options=["ALL"] + sorted(sku["category"].unique()),
    format_func=lambda x: category_map.get(x, x)
)

wh = st.sidebar.selectbox(
    "ì°½ê³ ",
    options=["ALL"] + sorted(inv["warehouse"].unique()),
    format_func=lambda x: warehouse_map.get(x, x)
)

sku_pick = st.sidebar.selectbox(
    "SKU",
    options=["ALL"] + sorted(sku["sku"].unique()),
    format_func=lambda x: "ì „ì²´" if x == "ALL" else x
)

# Build WHERE clauses
where_m = "WHERE 1=1"
if cat != "ALL":
    where_m += f" AND category = '{cat}'"
if sku_pick != "ALL":
    where_m += f" AND sku = '{sku_pick}'"

where_inv = f"WHERE date = '{latest_date}'"
if wh != "ALL":
    where_inv += f" AND warehouse = '{wh}'"
# --- KPIs (Summary) ---
kpi_sql = f"""
WITH base_sku AS (
  SELECT m.sku, m.sku_name, m.category
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND m.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
),
latest_inv AS (
  SELECT sku, SUM(onhand_qty) AS onhand_qty
  FROM inventory_daily
  WHERE date = '{latest_date}'
    {"AND warehouse = '"+wh+"'" if wh!="ALL" else ""}
  GROUP BY sku
),
demand_7d AS (
  SELECT sku, SUM(demand_qty) AS demand_7d
  FROM demand_daily
  WHERE date > '{latest_date}'::DATE - INTERVAL 7 DAY
  GROUP BY sku
),
inv_7d AS (
  SELECT i.date, SUM(i.onhand_qty) AS day_total
  FROM inventory_daily i
  JOIN base_sku b ON i.sku = b.sku
  WHERE i.date >= '{latest_date}'::DATE - INTERVAL 7 DAY AND i.date <= '{latest_date}'
    {"AND i.warehouse = '"+wh+"'" if wh!="ALL" else ""}
  GROUP BY i.date
),
inv_30d AS (
  SELECT i.date, SUM(i.onhand_qty) AS day_total
  FROM inventory_daily i
  JOIN base_sku b ON i.sku = b.sku
  WHERE i.date >= '{latest_date}'::DATE - INTERVAL 30 DAY AND i.date <= '{latest_date}'
    {"AND i.warehouse = '"+wh+"'" if wh!="ALL" else ""}
  GROUP BY i.date
)
SELECT
  COALESCE(SUM(COALESCE(li.onhand_qty,0)), 0) AS total_onhand,
  (SELECT COALESCE(ROUND(AVG(day_total), 0), 0) FROM inv_7d) AS inv_7d_avg,
  COALESCE(SUM(COALESCE(d7.demand_7d,0)), 0) AS total_demand_7d,
  (SELECT COALESCE(ROUND(AVG(day_total), 1), 0) FROM inv_30d) AS avg_onhand_30d,
  SUM(
    CASE
      WHEN COALESCE(d7.demand_7d,0) = 0 THEN 0
      WHEN (COALESCE(li.onhand_qty,0) / NULLIF(d7.demand_7d/7.0, 0)) < 7 THEN 1
      ELSE 0
    END
  ) AS stockout_risk_sku_cnt
FROM base_sku b
LEFT JOIN latest_inv li ON b.sku = li.sku
LEFT JOIN demand_7d d7 ON b.sku = d7.sku
"""
kpi = con.execute(kpi_sql).fetchdf().iloc[0]

# --- Demand trend (Last 60 Days) ---
trend_sql = f"""
WITH base_sku AS (
  SELECT m.sku
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND m.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
)
SELECT d.date, SUM(d.demand_qty) AS demand_qty
FROM demand_daily d
JOIN base_sku b ON d.sku = b.sku
WHERE d.date >= '{latest_date}'::DATE - INTERVAL 60 DAY
GROUP BY d.date
ORDER BY d.date
"""
trend = con.execute(trend_sql).fetchdf()

# --- Inventory trend (Last 60 Days) ---
inv_trend_sql = f"""
WITH base_sku AS (
  SELECT m.sku
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND m.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
)
SELECT i.date, SUM(i.onhand_qty) AS onhand_qty
FROM inventory_daily i
JOIN base_sku b ON i.sku = b.sku
WHERE i.date >= '{latest_date}'::DATE - INTERVAL 60 DAY
  {"AND i.warehouse = '"+wh+"'" if wh!="ALL" else ""}
GROUP BY i.date
ORDER BY i.date
"""
inv_trend = con.execute(inv_trend_sql).fetchdf()

# --- Top SKUs by demand (Last 30 Days) ---
top_sql = f"""
WITH base_sku AS (
  SELECT m.sku
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
)
SELECT d.sku, SUM(d.demand_qty) AS demand_30d
FROM demand_daily d
JOIN base_sku b ON d.sku = b.sku
WHERE d.date > '{latest_date}'::DATE - INTERVAL 30 DAY
GROUP BY d.sku
ORDER BY demand_30d DESC
LIMIT 10
"""
top = con.execute(top_sql).fetchdf()

# --- Top SKUs by inventory (Last 30 Days) ---
top_inv_sql = f"""
WITH base_sku AS (
  SELECT m.sku
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
)
SELECT i.sku, SUM(i.onhand_qty) AS onhand_30d
FROM inventory_daily i
JOIN base_sku b ON i.sku = b.sku
WHERE i.date >= '{latest_date}'::DATE - INTERVAL 30 DAY AND i.date <= '{latest_date}'
  {"AND i.warehouse = '"+wh+"'" if wh!="ALL" else ""}
GROUP BY i.sku
ORDER BY onhand_30d DESC
LIMIT 10
"""
top_inv = con.execute(top_inv_sql).fetchdf()


# --- IN/OUT trend (inventory_txn, last 60 days, filter by cat/wh/sku_pick) ---
txn_in_trend = None
txn_out_trend = None

if inv_txn is not None and len(inv_txn) > 0:
    txn_trend_sql = f"""
    WITH filtered AS (
      SELECT
        CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE) AS dt,
        CAST(t.qty AS DOUBLE) AS qty
      FROM inventory_txn t
      WHERE CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE)
            BETWEEN '{latest_date}'::DATE - INTERVAL 60 DAY AND '{latest_date}'::DATE
        {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
        {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
        {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
    )
    SELECT
      dt AS date,
      SUM(CASE WHEN qty > 0 THEN qty ELSE 0 END) AS in_qty,
      SUM(CASE WHEN qty < 0 THEN ABS(qty) ELSE 0 END) AS out_qty
    FROM filtered
    GROUP BY dt
    ORDER BY dt
    """

    txn_trend = con.execute(txn_trend_sql).fetchdf()

    # qtyê°€ 0ë§Œ ìžˆëŠ” ê²½ìš° ì‚¬ìš©ìžì—ê²Œ ëª…í™•ížˆ ì•ˆë‚´
    if txn_trend.empty or ((txn_trend["in_qty"].fillna(0).sum() == 0) and (txn_trend["out_qty"].fillna(0).sum() == 0)):
        txn_in_trend = None
        txn_out_trend = None
    else:
        txn_in_trend = txn_trend[["date", "in_qty"]].rename(columns={"in_qty": "qty"})
        txn_out_trend = txn_trend[["date", "out_qty"]].rename(columns={"out_qty": "qty"})

# --- Stockout Risk Table (Risk Tab) ---
risk_sql = f"""
WITH base_sku AS (
  SELECT m.sku, m.sku_name, m.category
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND m.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
),
latest_inv AS (
  SELECT sku, warehouse, onhand_qty
  FROM inventory_daily
  WHERE date = '{latest_date}'
    {"AND warehouse = '"+wh+"'" if wh!="ALL" else ""}
),
avg_daily_demand AS (
  SELECT sku, AVG(demand_qty) AS avg_daily_demand_14d
  FROM demand_daily
  WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY
  GROUP BY sku
),
base AS (
  SELECT
    b.sku, b.sku_name, b.category,
    li.warehouse,
    COALESCE(li.onhand_qty, 0) AS onhand_qty,
    COALESCE(ad.avg_daily_demand_14d, 0) AS avg_daily_demand_14d,
    CASE
      WHEN COALESCE(ad.avg_daily_demand_14d, 0) = 0 THEN NULL
      ELSE ROUND(COALESCE(li.onhand_qty,0) / ad.avg_daily_demand_14d, 1)
    END AS coverage_days
  FROM base_sku b
  LEFT JOIN latest_inv li ON b.sku = li.sku
  LEFT JOIN avg_daily_demand ad ON b.sku = ad.sku
)
SELECT *
FROM base
ORDER BY coverage_days ASC NULLS LAST
"""
risk = con.execute(risk_sql).fetchdf()

def assign_risk_level(days):
    if pd.isna(days):
        return "Low"
    if days < 3:
        return "Critical"
    if days < 7:
        return "High"
    if days < 14:
        return "Medium"
    return "Low"

risk["risk_level"] = risk["coverage_days"].apply(assign_risk_level)



# --- Reorder Suggestions Table (Reorder Tab) ---
reorder_sql = f"""
WITH base_sku AS (
  SELECT m.sku, m.sku_name, m.category
  FROM sku_master m
  WHERE 1=1
    {"AND m.category = '"+cat+"'" if cat!="ALL" else ""}
    {"AND m.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
    {"AND EXISTS (SELECT 1 FROM inventory_daily i WHERE i.sku = m.sku AND i.warehouse = '"+wh+"')" if wh!="ALL" else ""}
),
latest_inv AS (
  SELECT sku, warehouse, onhand_qty
  FROM inventory_daily
  WHERE date = '{latest_date}'
    {"AND warehouse = '"+wh+"'" if wh!="ALL" else ""}
),
avg_daily_demand AS (
  SELECT sku, AVG(demand_qty) AS avg_daily_demand_14d
  FROM demand_daily
  WHERE date > '{latest_date}'::DATE - INTERVAL 14 DAY
  GROUP BY sku
),
base AS (
  SELECT
    b.sku, b.sku_name, b.category,
    li.warehouse,
    COALESCE(li.onhand_qty, 0) AS onhand_qty,
    COALESCE(ad.avg_daily_demand_14d, 0) AS avg_daily_demand_14d,
    ROUND(COALESCE(ad.avg_daily_demand_14d, 0) * 10, 0) AS reorder_point,
    CASE
      WHEN COALESCE(ad.avg_daily_demand_14d, 0) = 0 THEN NULL
      ELSE ROUND(COALESCE(li.onhand_qty,0) / ad.avg_daily_demand_14d, 1)
    END AS coverage_days
  FROM base_sku b
  LEFT JOIN latest_inv li ON b.sku = li.sku
  LEFT JOIN avg_daily_demand ad ON b.sku = ad.sku
),
suggest AS (
  SELECT *,
    GREATEST(reorder_point - onhand_qty, 0) AS recommended_reorder_qty
  FROM base
)
SELECT
  sku, sku_name, category, warehouse,
  onhand_qty, reorder_point,
  avg_daily_demand_14d, coverage_days,
  recommended_reorder_qty
FROM suggest
WHERE (onhand_qty < reorder_point OR (coverage_days IS NOT NULL AND coverage_days < 10))
ORDER BY coverage_days ASC NULLS LAST, recommended_reorder_qty DESC
LIMIT 50
"""
reorder_suggest = con.execute(reorder_sql).fetchdf()

# --- Tabs ---
tab_summary, tab_risk, tab_reorder = st.tabs(["Overview", "ìž¬ê³  ë¦¬ìŠ¤í¬ ë¶„ì„", "ë°œì£¼ í•„ìš” ë¶„ì„"])

with tab_summary:
    st.subheader("KPI Overview")
    col1, col2, col3, col4, col5 = st.columns(5)

    # NaN / None ì•ˆì „ ì²˜ë¦¬
    total_onhand = int(pd.to_numeric(kpi["total_onhand"], errors="coerce")) if pd.notna(kpi["total_onhand"]) else 0
    inv_7d_avg = int(pd.to_numeric(kpi["inv_7d_avg"], errors="coerce")) if pd.notna(kpi["inv_7d_avg"]) else 0
    total_demand_7d = int(pd.to_numeric(kpi["total_demand_7d"], errors="coerce")) if pd.notna(kpi["total_demand_7d"]) else 0
    avg_onhand_30d = float(pd.to_numeric(kpi["avg_onhand_30d"], errors="coerce")) if pd.notna(kpi["avg_onhand_30d"]) else 0
    stockout_cnt = int(pd.to_numeric(kpi["stockout_risk_sku_cnt"], errors="coerce")) if pd.notna(kpi["stockout_risk_sku_cnt"]) else 0

    col1.metric("ì´ ìž¬ê³  ìˆ˜ëŸ‰", f"{total_onhand:,}")
    col2.metric("ìµœê·¼ 7ì¼ ìž¬ê³  ìˆ˜ëŸ‰", f"{inv_7d_avg:,}")
    col3.metric("ìµœê·¼ 7ì¼ ìˆ˜ìš”ëŸ‰", f"{total_demand_7d:,}")
    col4.metric("ìµœê·¼ 30ì¼ í‰ê·  ìž¬ê³ ", f"{avg_onhand_30d:,.1f}")
    col5.metric("í’ˆì ˆ ìœ„í—˜ SKUìˆ˜ (7ì¼ ì´ë‚´)", stockout_cnt)


    # ìˆ˜ìš” ì¶”ì´ / ìž¬ê³  ì¶”ì´ (ë°˜Â·ë°˜)
    col_trend_demand, col_trend_inv = st.columns(2)
    with col_trend_demand:
        fig_trend = px.line(trend, x="date", y="demand_qty", title="ìˆ˜ìš” ì¶”ì´ (ìµœê·¼ 60ì¼)")
        fig_trend.update_layout(xaxis_title="ì¼ìž", yaxis_title="ìˆ˜ìš”ëŸ‰")
        fig_trend.update_xaxes(tickformat="%Y-%m-%d")
        fig_trend = apply_plotly_theme(fig_trend)
        st.plotly_chart(fig_trend, use_container_width=True)
    with col_trend_inv:
        fig_inv_trend = px.line(inv_trend, x="date", y="onhand_qty", title="ìž¬ê³  ì¶”ì´ (ìµœê·¼ 60ì¼)")
        fig_inv_trend.update_layout(xaxis_title="ì¼ìž", yaxis_title="ìž¬ê³  ìˆ˜ëŸ‰")
        fig_inv_trend.update_xaxes(tickformat="%Y-%m-%d")
        fig_inv_trend = apply_plotly_theme(fig_inv_trend)
        st.plotly_chart(fig_inv_trend, use_container_width=True)

# --- IN/OUT trend (inventory_txn, last 60 days, filter by cat/wh/sku_pick) ---
txn_in_trend = None
txn_out_trend = None

if inv_txn is not None and len(inv_txn) > 0:
    txn_trend_sql = f"""
    WITH filtered AS (
      SELECT
        CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE) AS dt,
        UPPER(TRIM(CAST(t.txn_type AS VARCHAR))) AS txn_type_norm,
        TRY_CAST(t.qty AS DOUBLE) AS qty,
        t.sku,
        t.warehouse
      FROM inventory_txn t
      WHERE CAST(COALESCE(t.date, CAST(t.txn_datetime AS DATE)) AS DATE)
            BETWEEN '{latest_date}'::DATE - INTERVAL 60 DAY AND '{latest_date}'::DATE
        {"AND t.warehouse = '"+wh+"'" if wh!="ALL" else ""}
        {"AND t.sku = '"+sku_pick+"'" if sku_pick!="ALL" else ""}
        {"AND EXISTS (SELECT 1 FROM sku_master m WHERE m.sku = t.sku AND m.category = '"+cat+"')" if cat!="ALL" else ""}
    )
    SELECT
      dt AS date,
      SUM(
        CASE
          WHEN txn_type_norm IN ('IN', 'RETURN') THEN ABS(COALESCE(qty, 0))
          WHEN txn_type_norm = 'ADJUST' AND COALESCE(qty, 0) > 0 THEN COALESCE(qty, 0)
          ELSE 0
        END
      ) AS in_qty,
      SUM(
        CASE
          WHEN txn_type_norm IN ('OUT', 'SCRAP') THEN ABS(COALESCE(qty, 0))
          WHEN txn_type_norm = 'ADJUST' AND COALESCE(qty, 0) < 0 THEN ABS(COALESCE(qty, 0))
          ELSE 0
        END
      ) AS out_qty
    FROM filtered
    GROUP BY dt
    ORDER BY dt
    """

    txn_trend = con.execute(txn_trend_sql).fetchdf()

    # ê°’ì´ ì „ë¶€ 0ì´ë©´ ì°¨íŠ¸ ëŒ€ì‹  ì•ˆë‚´ ë¬¸êµ¬
    if txn_trend.empty or ((txn_trend["in_qty"].fillna(0).sum() == 0) and (txn_trend["out_qty"].fillna(0).sum() == 0)):
        txn_in_trend = None
        txn_out_trend = None
    else:
        txn_in_trend = txn_trend[["date", "in_qty"]].rename(columns={"in_qty": "qty"})
        txn_out_trend = txn_trend[["date", "out_qty"]].rename(columns={"out_qty": "qty"})


    # Top 10 SKUs - Demand
    fig_top = px.bar(top, x="sku", y="demand_30d", title="ìˆ˜ìš” TOP 10 SKU (ìµœê·¼ 30ì¼)")
    fig_top.update_layout(xaxis_title="SKU", yaxis_title="ìˆ˜ìš”ëŸ‰ (ìµœê·¼ 30ì¼)")
    fig_top.update_traces(width=0.5)
    fig_top = apply_plotly_theme(fig_top)
    st.plotly_chart(fig_top, use_container_width=True)

    # Top 10 SKUs - Inventory
    fig_top_inv = px.bar(top_inv, x="sku", y="onhand_30d", title="ìž¬ê³  TOP 10 SKU (ìµœê·¼ 30ì¼)")
    fig_top_inv.update_layout(xaxis_title="SKU", yaxis_title="ìž¬ê³  ìˆ˜ëŸ‰ (ìµœê·¼ 30ì¼ í•©ê³„)")
    fig_top_inv.update_traces(width=0.5)
    fig_top_inv = apply_plotly_theme(fig_top_inv)
    st.plotly_chart(fig_top_inv, use_container_width=True)

with tab_risk:
    st.subheader("âš ï¸ ìž¬ê³  ë¦¬ìŠ¤í¬ ëª©ë¡")
    col_left, col_filter = st.columns([2, 1])
    with col_filter:
        risk_period = st.selectbox(
            "ìž¬ê³  ì†Œì§„ ê¸°ì¤€(ì¼ìˆ˜)",
            options=[7, 14, 21, 30, 60],
            format_func=lambda x: f"{x}ì¼ ì´ë‚´",
            key="risk_period",
        )
        risk_level = st.selectbox(
            "Risk Level",
            options=["ì „ì²´", "Critical", "High", "Medium", "Low"],
            key="risk_level",
        )
    risk_filtered = risk[
        (risk["coverage_days"].notna()) & (risk["coverage_days"] < risk_period)
    ].copy()
    if risk_level != "ì „ì²´":
        risk_filtered = risk_filtered[risk_filtered["risk_level"] == risk_level]
    st.caption("ì»¤ë²„ë¦¬ì§€ ì¼ìˆ˜ = í˜„ìž¬ ìž¬ê³  / ìµœê·¼ 14ì¼ í‰ê·  ì¼ìˆ˜ìš” | Risk Level: Critical 0~3ì¼, High 3~7ì¼, Medium 7~14ì¼, Low 14ì¼ ì´ìƒ")
    st.dataframe(risk_filtered, use_container_width=True)

with tab_reorder:
    st.subheader("ðŸ”„ ë°œì£¼ í•„ìš” ëª©ë¡")
    st.caption("ì¶”ì²œ ë°œì£¼ ìˆ˜ëŸ‰ = max(ìž¬ì£¼ë¬¸ ê¸°ì¤€ - í˜„ìž¬ ìž¬ê³ , 0)")
    st.dataframe(reorder_suggest, use_container_width=True)
